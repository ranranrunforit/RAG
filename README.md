## RAG Projects


**[RAG Agents with LLMs](./RAG%20Agents%20with%20LLMs)**

- **Microservices and Environment Setup:** Establishing a robust execution environment 
- **LLM Interaction and Embedding Models:** Accessing and working with NVIDIAâ€™s endpoints and embedding models   
- **Document Processing and Vector Stores:** Loading, chunking, and indexing documents for semantic retrieval  
- **Semantic Guardrailing:** Implementing safety checks to filter out potentially harmful or irrelevant responses in chatbots. 


**[RAG with NVIDIA NIM and LangChain](./RAG%20with%20Langchain%20NVIDIA%20NIM)**

This project creates of Retrieval-Augmented Generation (RAG) applications using NVIDIA NIM microservices and LangChain. 
It focus on leveraging NVIDIA AI Endpoints for various tasks, including document retrieval, embedding generation, 
and conversational AI, with practical workflows for both cloud-hosted and locally deployed NIM models.

**[End-to-End RAG system](./End-to-End%20RAG%20system)**

The project focuses on factual question-answering (QA) specifically related to Pittsburgh and CMU. 
The system retrieves relevant documents and generates answers based on those documents. 
Large language models (LLMs) are used to enhance the knowledge base with relevant documents, 
improving the accuracy of answers related to history, culture, trivia, and upcoming events.
