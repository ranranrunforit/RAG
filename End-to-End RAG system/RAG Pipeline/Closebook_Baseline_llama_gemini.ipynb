{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoJO-2CLihs3"
      },
      "source": [
        "# Baseline model without RAG\n",
        "\n",
        "This is a baseline model for the QA task without the RAG pipline.\n",
        "\n",
        "In order to compare, we test four models as the backbone model in the RAG pipeline: `meta-llama/Llama-3.2-3B-Instruct`, `meta-llama/Llama-3.1-8B-Instruct`, `gemini-2.0-flash`, and `gemini-2.0-flash-thinking-exp-01-21`. We also adopt the same data type (fp16) and the same config for setting up the tokenizer. We use the same prompt format as the one in the RAG pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### meta-llama/Llama-3.2-3B-Instruct model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534,
          "referenced_widgets": [
            "bf18a8cce5e44ac6bf3989a17e9ebcde",
            "fadc689889a84252bfca07f235987108",
            "769b97368971499c968b8ee3c591bfa3",
            "445fe2849392490a9765291d26320cf1",
            "7e660ea8cc4b4567b686d14101ff35c3",
            "d029aff1ae524ab8b0444fcab07bcd75",
            "19bfe0cb2c814410ae9bcfde3b2d0ede",
            "a467ea4975454671a7b536083e99eaeb",
            "bee439a52fb24d16a76c987fa6726a9e",
            "91e3cb0c135a47cabd2fce60cfd10a5c",
            "f0744d0aa7144366b45570e03fbc5812",
            "0cc3b069befc47c7ab4a7fa4577a8b7a",
            "239fd3fed1dc4e66adb94e8c5635297f",
            "94617f0301314c98a121b01e2bac4afc",
            "e797b143eea54637b529545c9a9ab9c1",
            "61fd0c82c67047febf7a9d7dba174101",
            "223179d9415b4b6993150a91b1b8e0d3",
            "5953c03a777745638d0901d381cf3a55",
            "9d399202ed27473cbd93b5b531b97f30",
            "fe9931bca22643e0976d70f945361e85",
            "cbbc2d9d721e4dc99d061388fb85fae7",
            "ef95fc7645fc48b4bdb7468ac3a660de",
            "5f0c0f59b9044b8384cb7b003e201cbb",
            "d530775256864365b333c29b53e16ab2",
            "4c14936f224142cfbfa7c07b1968dfd9",
            "4569fcc727af494d89780d28d4a667d5",
            "41cf10320d0b4c8c8526d9ca0dacaa7a",
            "87b68760598640d5be3dd71e5bbc7f7a",
            "86ca2328bd9d4017be74159e987f08a6",
            "f5fc6fa0a5ab4b128835a4bbe5b3395d",
            "992d9dbb52bb43db9990d9308a44e5ef",
            "eab442d9295547f1bd96597f49278557",
            "75edd64792de427191a0b845bb05e50a",
            "15a289964b6d42498ce76edc16e5d397",
            "3c8d603d3a8c4584abe88969aaf932ca",
            "b9926a26442a4422a3bd13bc919f8c64",
            "a745a24e21b6479a8e2a5595143d1619",
            "93588a11bb5a43ca9918adfde3604d77",
            "10c621ff4ac64b15b1a9bd97862d1c72",
            "7173bd2376d1456ba339856404d640af",
            "57c0062c08a84d23a9855c853739e788",
            "60215201a6c14d8f818885b1105c88dc",
            "e31e0a6b9154406693126f31c90f7d9b",
            "0d2435122a264c7fa5a84e01487c34f0",
            "09c0f848f7494c0392557f14c7321da5",
            "262595d559664c1194e947546993b662",
            "418bcd6414f3478c848213e9d8e91f85",
            "0416e5b9fc1a451b9ce1aa99094304ea",
            "9a8afa6c481c4b68b7bd0263a1194ebf",
            "2b707f715ab94527b025578e51bfae29",
            "e2af95ea8fd242709bb07f7927dba140",
            "965b6f2d24434ffeae60ecee379e933b",
            "4e8a075318e84d7f9c408c6ad9a2e9c5",
            "e8bebc6a21eb4bcdb8b9b55791f5429a",
            "5b312bcd1d924c25a5c3ce1b623d7568",
            "e4b2751f6ad34235867d75c84628f611",
            "80b04a10d7604c2da3f88cb0b16b80af",
            "0dec75e478c6440283475fd650e2783a",
            "7cabb3d83e6b41e592483bbc1a1bcd96",
            "3361cd35a4d941f398b94db72439ec3d",
            "2e465c35edf846baa051f0231f5d5306",
            "24e464b8375b4d34be0d9d4750e30723",
            "174a5186becf40029e8446ac581aaa16",
            "f58153329fe845a8bf908b1da33348de",
            "feab912f76514c1bbbb6d7a2c32b4004",
            "01760114f9e44bde8d4b5250b664ee47",
            "4331c9ea454748738bd41bc8ff2b2153",
            "cc3e9bee826b4464bf61bd0040dfabda",
            "9813a55872c44e83ab9ce04e4d18a642",
            "5fa645c96e9a4bf595e60ac352151b36",
            "02f9e6298a714dd7a35e765e64740328",
            "365abbf9e1114f8bbf5ce6bc8d5b4bcb",
            "56db73bcf9034162acfe7216897872eb",
            "fb80296d84984b05a7b8d8af083f9db9",
            "824a6202241b455d9766babb997b7d09",
            "99f7264fb70d4ef983ceefc3eabc3334",
            "895c4031afbf4f7ea16b689e618c92cd",
            "7f5f01c94eb24626908745d8d76bc89e",
            "c22b2d49fdfe4dc69296428bb5460f6d",
            "71bb1f1ca8b24bde8877106828397420",
            "ce3f652ae29e473db7a9bb6df4768f1c",
            "97804e501bb5477ba174d2395d803ab8",
            "9eec76660210497ebd13562bf2ef0d6b",
            "0dc61217a16146549cb244c594ddc0c9",
            "2d3d553be13a42198b8480c0cd735535",
            "d54f43ba099a4fac9e6def2018e31f21",
            "8214c97d5dad4afeb8854aefc2e0caaf",
            "e65b618d9d724abd9e7006e875845aef",
            "e48eea9b0dbe40bda9e3bfbc87e88d33",
            "c465ae192fb44328b7fa06cf0c3063d4",
            "c3282a9886f8422a8573dee964127cd9",
            "9d7af1980bc1493ca5489491d5188059",
            "c36474f866dc428a91671d998bcb1b4e",
            "8401e5c991c444bb8e8b708b1ffb820f",
            "948f655c2c6942cbb8c51e0c1d0fde3c",
            "64b2a5b405d3439da94d944785994f32",
            "515ebc0029e34bde97499567fa148f01",
            "24ea18af2f4f43cb9b3070dd5b5f18da",
            "44dec6d571d84336820d3cdb38090a30",
            "77b11a408c2d471e8aefc21717ad71cc",
            "7095fe1b3add4307b7217fe1c50d3382",
            "b37e31b6a2454fe0aea20bcf24645373",
            "1a1b0effd77b42d397142468565e8d88",
            "e80f7c0d1e124744848dd71b582ca8e7",
            "b5888d1d8aa1448c9e9e26e0220eda15",
            "8bd5d2143a3f4e0785c017aebca289cd",
            "7ab0783d71d444f69a3f154e444a24bc",
            "296da71038a7467cbdfcee8267da4561",
            "2867596842c846869fe7ef544cc09ac4",
            "2ddc4bb72733402e8ef3aa0e33fe4064"
          ]
        },
        "id": "-ZGP2d6Uihs9",
        "outputId": "a950e908-7284-42d6-aeb6-ad597ebd733b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf18a8cce5e44ac6bf3989a17e9ebcde",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cc3b069befc47c7ab4a7fa4577a8b7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f0c0f59b9044b8384cb7b003e201cbb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15a289964b6d42498ce76edc16e5d397",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09c0f848f7494c0392557f14c7321da5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4b2751f6ad34235867d75c84628f611",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4331c9ea454748738bd41bc8ff2b2153",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f5f01c94eb24626908745d8d76bc89e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e48eea9b0dbe40bda9e3bfbc87e88d33",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77b11a408c2d471e8aefc21717ad71cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from huggingface_hub import login\n",
        "\n",
        "\n",
        "model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "\n",
        "login(token=os.getenv(\"HUGGINGFACE_TOKEN\", \"your_huggingface_token\"))\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"left\"\n",
        "\n",
        "generation_pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.float16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7nxCaVPihtA"
      },
      "outputs": [],
      "source": [
        "# Step 3: load qa annotation test set\n",
        "import pandas as pd\n",
        "# qa_df = pd.read_csv(\"../data/annotated/QA_pairs_1.csv\")\n",
        "qa_df = pd.read_csv(\"./data/test/test_questions.csv\")\n",
        "\n",
        "# doc_ids = qa_df[\"Doc_id\"].tolist()\n",
        "questions = qa_df[\"Question\"].tolist()\n",
        "# answers = qa_df[\"Reference_Answers\"].tolist()\n",
        "\n",
        "# # random sample 10 qa pairs\n",
        "# import random\n",
        "# sample_size = 10\n",
        "# random.seed(747)\n",
        "# sample_indices = random.sample(range(len(questions)), sample_size)\n",
        "# sample_doc_ids = [doc_ids[i] for i in sample_indices]\n",
        "# sample_questions = [questions[i] for i in sample_indices]\n",
        "# sample_answers = [answers[i] for i in sample_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "054PtKuEihtB"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "You are an expert assistant answering factual questions about various aspects of Pittsburgh or Carnegie Mellon University (CMU), including history, policy, culture, events, and more.\n",
        "If you do not know the answer, just say \"I don't know.\"\n",
        "\n",
        "Important Instructions:\n",
        "- Answer concisely without repeating the question.\n",
        "- Do **not** use complete sentences. Provide only the word, name, date, or phrase that directly answers the question. For example, given the question \"When was Carnegie Mellon University founded?\", you should only answer \"1900\".\n",
        "\n",
        "Examples:\n",
        "Question: Who is Pittsburgh named after?\n",
        "Answer: William Pitt\n",
        "Question: What famous machine learning venue had its first conference in Pittsburgh in 1980?\n",
        "Answer: ICML\n",
        "Question: What musical artist is performing at PPG Arena on October 13?\n",
        "Answer: Billie Eilish\n",
        "\n",
        "Question: {question} \\n\\n\n",
        "Answer:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Houo_NaoihtB",
        "outputId": "3c937d62-a468-4ac7-8824-8cb13267414c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 10/574 [00:03<02:11,  4.29it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "100%|██████████| 574/574 [02:04<00:00,  4.60it/s]\n"
          ]
        }
      ],
      "source": [
        "# use the template to generate the answers\n",
        "from tqdm import tqdm\n",
        "generated_answers = []\n",
        "for question in tqdm(questions):\n",
        "    full_prompt = template.format(question=question)\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": full_prompt},\n",
        "        ]\n",
        "    output = generation_pipe(messages, max_new_tokens=50)\n",
        "    generated_answers.append(output[0][\"generated_text\"][1]['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zyss6uHihtC"
      },
      "outputs": [],
      "source": [
        "# write all columns to a csv file\n",
        "# results_df = pd.DataFrame({\n",
        "#         \"Doc_id\": doc_ids,\n",
        "#         \"Question\": questions,\n",
        "#         \"Reference_Answers\": answers,\n",
        "#         \"Generated_Answer\": generated_answers,\n",
        "#     })\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "        \"Question\": questions,\n",
        "        \"Generated_Answer\": generated_answers,\n",
        "    })\n",
        "\n",
        "# save the results to a csv file\n",
        "results_df.to_csv(\"./output/closebook_baseline.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "_WoKt-ztjHWW",
        "outputId": "ba6b7cf1-2237-43c9-8326-277c9692f74a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 574,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 570,\n        \"samples\": [\n          \"What was Pittsburgh known as in 1850 due to its industry?\",\n          \"What is the name of the bridge connecting the Allegheny County Courthouse to the prison?\",\n          \"When is the Georgia Tech Yellow Jackets vs Panthers game taking place?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Generated_Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 379,\n        \"samples\": [\n          \"Youth Football U\",\n          \"\\\"Steel Curtain\\\"\",\n          \"Derek Shelton\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "results_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9b5d5263-b2ad-4cce-8ede-ea7821428098\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Generated_Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What bank, which is the 5th largest in the US,...</td>\n",
              "      <td>PNC Bank</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How many bridges does Pittsburgh have?</td>\n",
              "      <td>403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who named the city of Pittsburgh?</td>\n",
              "      <td>General Robert Moore</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>At what park do the three rivers converge in P...</td>\n",
              "      <td>Point State Park</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How many neighborhoods does Pittsburgh have?</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>569</th>\n",
              "      <td>What is the primary focus of the event at the ...</td>\n",
              "      <td>Pittsburgh JazzLive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570</th>\n",
              "      <td>Where and when is the Pittsburgh Veg Fair held...</td>\n",
              "      <td>Pennsylvania State Farm Show Complex</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>571</th>\n",
              "      <td>How can restaurants get involved with Pittsbur...</td>\n",
              "      <td>Register online through VisitPittsburgh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>572</th>\n",
              "      <td>What are the benefits of sponsoring the Pittsb...</td>\n",
              "      <td>I don't know</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>573</th>\n",
              "      <td>What is the recommended action for attendees w...</td>\n",
              "      <td>I don't know</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>574 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b5d5263-b2ad-4cce-8ede-ea7821428098')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9b5d5263-b2ad-4cce-8ede-ea7821428098 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9b5d5263-b2ad-4cce-8ede-ea7821428098');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1a7b15a4-fbc4-4a88-8187-33e62c254071\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a7b15a4-fbc4-4a88-8187-33e62c254071')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1a7b15a4-fbc4-4a88-8187-33e62c254071 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_49f57435-5c5e-43da-b244-d8e9faea2e23\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_49f57435-5c5e-43da-b244-d8e9faea2e23 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              Question  \\\n",
              "0    What bank, which is the 5th largest in the US,...   \n",
              "1               How many bridges does Pittsburgh have?   \n",
              "2                    Who named the city of Pittsburgh?   \n",
              "3    At what park do the three rivers converge in P...   \n",
              "4         How many neighborhoods does Pittsburgh have?   \n",
              "..                                                 ...   \n",
              "569  What is the primary focus of the event at the ...   \n",
              "570  Where and when is the Pittsburgh Veg Fair held...   \n",
              "571  How can restaurants get involved with Pittsbur...   \n",
              "572  What are the benefits of sponsoring the Pittsb...   \n",
              "573  What is the recommended action for attendees w...   \n",
              "\n",
              "                            Generated_Answer  \n",
              "0                                   PNC Bank  \n",
              "1                                        403  \n",
              "2                       General Robert Moore  \n",
              "3                           Point State Park  \n",
              "4                                         19  \n",
              "..                                       ...  \n",
              "569                      Pittsburgh JazzLive  \n",
              "570     Pennsylvania State Farm Show Complex  \n",
              "571  Register online through VisitPittsburgh  \n",
              "572                             I don't know  \n",
              "573                             I don't know  \n",
              "\n",
              "[574 rows x 2 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz3gkc61O554"
      },
      "source": [
        "\n",
        "### meta-llama/Llama-3.1-8B-Instruct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXt0hyS8LcZz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from huggingface_hub import login\n",
        "\n",
        "\n",
        "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "\n",
        "login(token=os.getenv(\"HUGGINGFACE_TOKEN\", \"your_huggingface_token\"))\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"left\"\n",
        "\n",
        "generation_pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.float16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DJrB8eFLrta"
      },
      "outputs": [],
      "source": [
        "# Step 3: load qa annotation test set\n",
        "import pandas as pd\n",
        "qa_df = pd.read_csv(\"./data/annotated/QA_pairs_1.csv\")\n",
        "#qa_df = pd.read_csv(\"./data/test/test_questions.csv\")\n",
        "\n",
        "doc_ids = qa_df[\"Doc_id\"].tolist()\n",
        "questions = qa_df[\"Question\"].tolist()\n",
        "answers = qa_df[\"Reference_Answers\"].tolist()\n",
        "\n",
        "# random sample 10 qa pairs\n",
        "import random\n",
        "sample_size = 100\n",
        "random.seed(747)\n",
        "sample_indices = random.sample(range(len(questions)), sample_size)\n",
        "sample_doc_ids = [doc_ids[i] for i in sample_indices]\n",
        "sample_questions = [questions[i] for i in sample_indices]\n",
        "sample_answers = [answers[i] for i in sample_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzJSvj0INYCx"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "You are an expert assistant answering factual questions about various aspects of Pittsburgh or Carnegie Mellon University (CMU), including history, policy, culture, events, and more.\n",
        "If you do not know the answer, just say \"I don't know.\"\n",
        "\n",
        "Important Instructions:\n",
        "- Answer concisely without repeating the question.\n",
        "- Do **not** use complete sentences. Provide only the word, name, date, or phrase that directly answers the question. For example, given the question \"When was Carnegie Mellon University founded?\", you should only answer \"1900\".\n",
        "\n",
        "Examples:\n",
        "Question: Who is Pittsburgh named after?\n",
        "Answer: William Pitt\n",
        "Question: What famous machine learning venue had its first conference in Pittsburgh in 1980?\n",
        "Answer: ICML\n",
        "Question: What musical artist is performing at PPG Arena on October 13?\n",
        "Answer: Billie Eilish\n",
        "\n",
        "Question: {question} \\n\\n\n",
        "Answer:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txdxj1GtNdNs"
      },
      "outputs": [],
      "source": [
        "# use the template to generate the answers\n",
        "from tqdm import tqdm\n",
        "generated_answers = []\n",
        "for question in tqdm(questions):\n",
        "    full_prompt = template.format(question=question)\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": full_prompt},\n",
        "        ]\n",
        "    output = generation_pipe(messages, max_new_tokens=50)\n",
        "    generated_answers.append(output[0][\"generated_text\"][1]['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4vpmIJ-Ncv6"
      },
      "outputs": [],
      "source": [
        "# write all columns to a csv file\n",
        "results_df = pd.DataFrame({\n",
        "        \"Doc_id\": doc_ids,\n",
        "        \"Question\": questions,\n",
        "        \"Reference_Answers\": answers,\n",
        "        \"Generated_Answer\": generated_answers,\n",
        "    })\n",
        "\n",
        "# results_df = pd.DataFrame({\n",
        "#         \"Question\": questions,\n",
        "#         \"Generated_Answer\": generated_answers,\n",
        "#     })\n",
        "\n",
        "# save the results to a csv file\n",
        "results_df.to_csv(\"./output/llama31_8B_baseline.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-wB1p_gOiAT"
      },
      "outputs": [],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ikaCGeTOpNg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from huggingface_hub import login\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "def run_llama_baseline(model_name, output_file, qa_file=\"./data/annotated/QA_pairs_1.csv\", sample_size=100):\n",
        "    \"\"\"\n",
        "    Generate QA baseline answers using a specified model and save the results to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): Name of the Hugging Face model to use.\n",
        "        output_file (str): Path to save the generated answers.\n",
        "        qa_file (str): Path to the QA annotation test set CSV file.\n",
        "        sample_size (int): Number of QA pairs to sample for evaluation.\n",
        "    \"\"\"\n",
        "    # Login to Hugging Face Hub\n",
        "    login(token=os.getenv(\"HUGGINGFACE_TOKEN\", \"your_huggingface_token\"))\n",
        "\n",
        "    # Load the model and tokenizer\n",
        "    print(f\"Loading model: {model_name}\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.padding_side = \"left\"\n",
        "\n",
        "    # Initialize the text generation pipeline\n",
        "    generation_pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        torch_dtype=torch.float16\n",
        "    )\n",
        "\n",
        "    # Load QA annotation test set\n",
        "    print(f\"Loading QA file: {qa_file}\")\n",
        "    # Randomly sample QA pairs\n",
        "    random.seed(42)\n",
        "    qa_df = pd.read_csv(qa_file)\n",
        "    qa_df = qa_df.sample(sample_size, random_state=221)\n",
        "    sample_doc_ids = qa_df[\"Doc_id\"].tolist()\n",
        "    sample_questions = qa_df[\"Question\"].tolist()\n",
        "    sample_answers = qa_df[\"Reference_Answers\"].tolist()\n",
        "\n",
        "    #sample_indices = random.sample(range(len(questions)), sample_size)\n",
        "\n",
        "    #sample_doc_ids = [doc_ids[i] for i in sample_indices]\n",
        "    #sample_questions = [questions[i] for i in sample_indices]\n",
        "    #sample_answers = [answers[i] for i in sample_indices]\n",
        "\n",
        "    # Define the prompt template\n",
        "    template = \"\"\"\n",
        "    You are an expert assistant answering factual questions about various aspects of Pittsburgh or Carnegie Mellon University (CMU), including history, policy, culture, events, and more.\n",
        "    If you do not know the answer, just say \"I don't know.\"\n",
        "\n",
        "    Important Instructions:\n",
        "    - Answer concisely without repeating the question.\n",
        "    - Do **not** use complete sentences. Provide only the word, name, date, or phrase that directly answers the question. For example, given the question \"When was Carnegie Mellon University founded?\", you should only answer \"1900\".\n",
        "\n",
        "    Examples:\n",
        "    Question: Who is Pittsburgh named after?\n",
        "    Answer: William Pitt\n",
        "    Question: What famous machine learning venue had its first conference in Pittsburgh in 1980?\n",
        "    Answer: ICML\n",
        "    Question: What musical artist is performing at PPG Arena on October 13?\n",
        "    Answer: Billie Eilish\n",
        "\n",
        "    Question: {question} \\n\\n\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate answers\n",
        "    print(\"Generating answers...\")\n",
        "    generated_answers = []\n",
        "    for question in tqdm(sample_questions):\n",
        "        full_prompt = template.format(question=question)\n",
        "        messages = [\n",
        "            {\"role\": \"user\", \"content\": full_prompt},\n",
        "        ]\n",
        "        output = generation_pipe(messages, max_new_tokens=50)\n",
        "        generated_answers.append(output[0][\"generated_text\"][1]['content'])\n",
        "\n",
        "    # Save results to a CSV file\n",
        "    results_df = pd.DataFrame({\n",
        "        \"Doc_id\": sample_doc_ids,\n",
        "        \"Question\": sample_questions,\n",
        "        \"Reference_Answers\": sample_answers,\n",
        "        \"Generated_Answer\": generated_answers,\n",
        "    })\n",
        "    results_df.to_csv(output_file, index=False)\n",
        "    print(f\"Results saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759,
          "referenced_widgets": [
            "a407480febad4b4ab8ae2e3c6811d30f",
            "733adc6f305f4a07b111d28671ce986f",
            "3819944e82364cd5a45bfa3caa39b663",
            "19814d2336894af29d79ee7edf2c8073",
            "8491eab01c184994b47a354fabe1c270",
            "d5752c2470d54f59ac051ae24116ed8e",
            "3c8e17084ad04605aa79be5c68b085c1",
            "40f2fb3e53584bb89a72b2cfe51cc89b",
            "2e9f2cd6ba9940c5b2510e35bd4076e8",
            "4bf0c940b2d94d89b4a12747960d81ff",
            "f2b79cac740f4b35a693506c367cdcde",
            "b307a36810dc4fccbe8f45d058122d1d",
            "c600711682984426ae2cc9c1f0eedb9c",
            "cd9e030b1b1f4d2889f5ba9a5bb79310",
            "ac82f348135e472b804c18addb095657",
            "c9b77874c980467ba2c036bc7a8f4041",
            "917fe2f2f91948ecb5fabca9113e459d",
            "5f8ca60e6ea5436cb2854fa43c71ec90",
            "938a60263d9e4082a8ebe72430886483",
            "d93592b988a74163a71179addb4df8a2",
            "566ebf45f2454777b4db8717651cc53c",
            "e66ef5c7e49e465cafc658be0b27e5e2",
            "6497c74d215e486280213f789e844db6",
            "9cc33fb2ab1d4224a42af666ea7bd3d1",
            "56cdd99b2ff34d27ad9e56065cbbd6d3",
            "12e6c454d5d1471386ec2f772868825c",
            "8abbb868c0bc4401922fe7a601c6a925",
            "d1787df23f4544a3a7c1111b762f3e31",
            "aa679efaeb044dd8996cad36478dd26b",
            "eb1ad87664364ea9816b8c2e5c479d22",
            "b4ee3baa24f64d8b82c4d86e9e405f34",
            "d53f701ea66c477488a220ae4605b35a",
            "1f8d4475bbb14f87be54e5a33a7c20fc",
            "1b142e0f5f1e4da49927d86fe7ff8326",
            "d937a7df844948a391780174ee0fa0c6",
            "1652b4d58b95422e8942f079e28812fb",
            "a71ca5f13f0c430eaf80a0f1692f2ef4",
            "5b9322cf58d149768684b08e7de471ea",
            "e70bdaa29c1849cd85a5a2e46502142b",
            "1fae7841dae540fcaeb4ac0f7e3ea31a",
            "c042e1f294a041818ddad7ab44087b07",
            "38ebde626b2940188b955fae3fe4a130",
            "50f651f639334fc5934795459fb58bcc",
            "eb9db753065e4a85bd7ac21b9fb7f6f8",
            "a4bda63a4c2a4715a8bc5d346653f3ed",
            "88052a4579ab4dfe8877a51d9e31cee9",
            "a9c72df541214c0dad4eac89c7439dd5",
            "f4514383007d42e0a56f450f7cd12233",
            "9982d94275884210a84aec93235e4d5e",
            "201628f843164d5aa3a77d018ec822e5",
            "485f998f5c9346dca731a551c003ba05",
            "82c52e717151495b841dac67979d5234",
            "56c59db4432846b99ad10ff82cc51acc",
            "ac511c2f44bb4ad68f45659ed294ca9e",
            "1034811758db4ce1a0db81f653a8e913",
            "e16fa4af9500434cb04e7962ccf4628c",
            "74e075201b6b4fc1aa0d3a275f07fc3f",
            "204cb071b2ab4407984a4ac887299445",
            "ff0fd12e9b664dfe952f9a71f0b12fe9",
            "f7390e428a8b432c8cba47cddb84eb16",
            "3b3aef1ad84b48109706546ee9694b06",
            "648a9d574e0948b6a3b5438bb9fa2db1",
            "6c5eace1dbf14f7692ce66ecc8b18a12",
            "06b0fa33a23b414d8e3f6fc2cfa8011c",
            "cc78db172b5149f78b023599598c0da8",
            "a6b93ca3aea84289b77dfc834b630f63",
            "d6f4c8d070ea49428ac63390c175c6f7",
            "25faa2e776bc419080f8b08dc56bd8d1",
            "7c5409c992b04e76891111e0931ca644",
            "6ed6a8d3ecb84bc3bbafc4192e805cdf",
            "00967dbfbb234c239e172e39eb581dff",
            "3afebd94210246ebbbd1360bbc838a9b",
            "72c6b6d895dd4ae2813f58ce7bec491b",
            "d66be66beaeb474b97c67a51ed3ef4c8",
            "b8c4ae8041434a78bdd41ea849ea772f",
            "fda1acaa20ce44fe93bc5d9e7f1b6fda",
            "441d0a82fd834ffebac3521aa870825e",
            "f1cb70582f5f46069f3eab67b266cb30",
            "66e4da38d57741f381fd065a6ac7e6e1",
            "e389d5c3209d49cc9642c4eb5d0522ba",
            "1804377508b843f5803def8a13809572",
            "32ac0b82d6e84e6f82ecc95a6e01aa0c",
            "62ea4465c8a9412998830e2ac22feea8",
            "1c10f75f6b71493ba47e572ce5c77d31",
            "94ee67c4bdce4febacb8794821edc387",
            "530e35b5f9a94f0abe379b7d9fb3ed23",
            "17bf02bb3e47434abf3a937c2783494d",
            "72707f4dbe4549f696ad3b578859d94e",
            "55894fde8295431e9c033aef8e9c6736",
            "4914ac00d1d14717938917065a8a29f9",
            "98f5f2f41498467d81936e8e78480965",
            "41b8300937794592b8d25e9f89813245",
            "26ebac7f8761475da6bc9a2767652352",
            "95508e168cf04b65b73fd5e95a6efd3d",
            "4957191fc7944453be06747dbe216c8f",
            "858d08474fbb4a65ab3cec1395a57a06",
            "f1b5fe492616412dbf91acad59b1c0bd",
            "0897208c8a9c47bc94281a805b6ca64d",
            "2ed46e4812b74aba98e0d95d0a9a3147",
            "55680538e62d40a99781b7cf9a99dbd5",
            "9a379767a74f435d80999b0ca784d2eb",
            "db0103d5a5e44e1ab6f335c475b86ce0",
            "5a421be332b94d37aade7f61c974ed36",
            "d6385dd06dcf4c7abb1f62811e0c7a59",
            "b40d5d0f00884746aec09d3c59a08daf",
            "2ca7b6280c2847028290b75d4ba38346",
            "17c2abe40f7849a6a3b71f068fefcce0",
            "b19b269cee6e48809696fade16e6df55",
            "9bfb425498d247119c5b3275ae513312",
            "7fc719e49fb4474693fbb8d00fafecdf",
            "7169f97f8f6d491289f070325638198c",
            "88f739cd9f7c4b6e9691d0d34f2aae09",
            "86d8e836262446c3b3dcec6ee4ffb89a",
            "49e41fb64d054c44913089ba64bf9e0a",
            "9d16a6562fd24c75afd31bc604dffaed",
            "75d11e90e628423e8ba4b2c9537b3d2b",
            "ef2eca82bd334e148b4fe594ff97e31e",
            "e0f94e3134374eb89b9d1bdb659c4086",
            "151e42209bdd44c6b43a92c290616f87",
            "ed349fa90c3542d28d45e408c8276726",
            "14753789a4ad4581ae94fff10d2d7436",
            "dc1e4cb3cd3f4ca189722840b9d08306",
            "6fb18edd60624ba391dac8cc8dc6991c",
            "05041c0a14074af2894d1e8d6ef154a2",
            "ff7b9c418bc24d058ce6362aa83ff821",
            "8c8aeb9f44584d71bb37c1a99fd4fdf8",
            "866aa0569d1344dfbd29ea8f82bfe389",
            "c260ecb9a77141c682441910454c6dcf",
            "4650b0d0f1ba48198682dc52b7f5d015",
            "1d4ecb48261149bdbe85209be123850b",
            "968e93c1b1ca4a288173ac4ac34e1986",
            "e4e5696c7ec64980b58bd48aa05fdd12"
          ]
        },
        "id": "N8-VZi7SQJOQ",
        "outputId": "a911cd6c-3662-4778-d615-7f7d0de7edee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model: meta-llama/Llama-3.1-8B-Instruct\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a407480febad4b4ab8ae2e3c6811d30f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b307a36810dc4fccbe8f45d058122d1d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6497c74d215e486280213f789e844db6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b142e0f5f1e4da49927d86fe7ff8326",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4bda63a4c2a4715a8bc5d346653f3ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e16fa4af9500434cb04e7962ccf4628c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6f4c8d070ea49428ac63390c175c6f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1cb70582f5f46069f3eab67b266cb30",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55894fde8295431e9c033aef8e9c6736",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55680538e62d40a99781b7cf9a99dbd5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7169f97f8f6d491289f070325638198c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc1e4cb3cd3f4ca189722840b9d08306",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading QA file: ./data/annotated/QA_pairs_1.csv\n",
            "Generating answers...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 10/100 [00:04<00:40,  2.21it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "100%|██████████| 100/100 [00:24<00:00,  4.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to ./output/llama31_8B_baseline.csv\n"
          ]
        }
      ],
      "source": [
        "# Define the models and output file names\n",
        "models = [\n",
        "    (\"meta-llama/Llama-3.2-3B-Instruct\", \"./output/llama32_3B_baseline.csv\"),\n",
        "    (\"meta-llama/Llama-3.1-8B-Instruct\", \"./output/llama31_8B_baseline.csv\")#,\n",
        "    #(\"meta-llama/Llama-3.3-70B-Instruct\", \"./output/llama33_70B_baseline.csv\")\n",
        "]\n",
        "\n",
        "# Run the function for each model\n",
        "for model_name, output_file in models:\n",
        "    run_llama_baseline(model_name, output_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G9Qy1w024rz"
      },
      "source": [
        "### meta-llama/Llama-3.3-70B-Instruct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b982d4610ec4443691265d6c4a55edfa",
            "d714428adee849bdb6bee3dbbeeacdc1",
            "9739fb4cc7424737844336407dc17709",
            "9bf5c68c85ba484da830e565944b614b",
            "7de1d7af29974ac6af636ddfe58cf199",
            "ff2cb07643bb4546a1be79c77364ba3e",
            "33427bb3a6174257bc5e75ebc1f606c3",
            "7dda6cf879ae4bb294bcaeb5a1aee614",
            "ecf8fb1bd6dd4bb7b756deb1a92be60e",
            "f40c3b31145145678c643577cd82e04e",
            "6d23a9da3018427aa71d8260382ac469",
            "b40361687e1f4f1cb61d6ac4e7572e92",
            "380e774cca94475d9792dc98ee0f98e7",
            "84215a2cfd044be0bee3aa55b6401ed7",
            "cc10731a928448068fe9be7e84844a22",
            "68e6ade8b41c49ad9d081dbaf4593bf1",
            "f6d0f7697b4b4e2fbf16d48b69027dca",
            "bc91a21412d24a99abf53abca356fe08",
            "a050fdeced9442d48b67c8445905ba2c",
            "c068b73c65cb4272b4ad5814d53ad75a",
            "0256e138d05642a6981311107a7a2a34",
            "c3deabf6a50a407bb0216ce5f889de25",
            "eb8d27668e4e4649bac9f51e96ab6db0",
            "95d823c3d55146ada9d4ccacfc041377",
            "036584d568c44a1ab875b2a5f9274b2b",
            "2f0ff6b06ecc4a0fa9673952117996d8",
            "e1db70b7a34246679991b407c48c8aeb",
            "bbf9e028daeb4d64ae671e81dd2fb48b",
            "a110214a3b7e4cbc9b1e7722feb1c020",
            "67f42baa0c1343ff84d9170c7d31a144",
            "627008665aff4e1096028245fe817a68",
            "6c204a7e89b84a4cb627974fa794ad7b",
            "ce8824dc41c54743aeddc52f122ed13f",
            "1b54e8052e9f441b9e3c2446afabd692",
            "01debf33fdf041de83ff93dd5dbc139d",
            "fc3856d72ad04bc1b622afba5388c53d",
            "5ecdf4c4ec594c91945879fd959cc1c3",
            "50d3cb62d2724c63872027a90aef70d3",
            "dd58c1281ca34986beb5f34b7f5f6168",
            "8264967daed442e69e4fe132aba199fc",
            "13f51b08cf8b44e98b4541121ec7f395",
            "0bde0bb3c16941728d2b68218dd74d19",
            "da26f2457535405c89448a376f3948ad",
            "2b7b8474d6384c578384676b8874c1d1",
            "c77b231995594213a661a05f3ab2ef05",
            "681d69ad41ed4f3da66717ba660b9e56",
            "2f60026cdc54405aa7e0729e0ea1d413",
            "0e5c88065b234fc1b467f30f7fd9001e",
            "a4c989ef0e684561928944417564ed38",
            "66e1dd905c4e4088b8383151d6af2de9",
            "d455040550ab48189a786129d7eb21c5",
            "e3df8f92d9624b70b56e299086098c3e",
            "d9bae54f26164328bf09c5b44fdd8a0b",
            "5341d595ea6c4a8da33a2d7478018368",
            "1a2f959ff780441aacf5c13f378aed23",
            "5255660e24bf4fdebdd1d4e18836bd5d",
            "8affb2000e364d07b662f03a0127cfb2",
            "e0d21b4f31274707ac05417211802d47",
            "4cb9fc8c9c8e4c2382b568ef2230b972",
            "daa8c541b49b4f25b90b6464d99adac3",
            "911f78ceee644d52a5fce731d544d67a",
            "84b166bda650474a8998eb8abd801628",
            "7e3b0869230b4e69845cecc455a74b4f",
            "6112ec4bd0b0404da705e41f05fd2957",
            "867a76770bc343f7a74b0ba03bd51db3",
            "49e9c09ecdf14ec8bd6a14f473e32d21",
            "40c7676bf71340b3a6b14cfac4d03a9a",
            "3ea5569b17524756a31e53409a27219f",
            "54efc30229bc4b828b812a6601177d92",
            "7ca617cb08f14ed38e5f3890f67dacdf",
            "f78c2461bfc7472eb0e04966d2596fb8",
            "4c1d505b52334ddbb8c863ef7e3c9c75",
            "6a060e4c104e40d19583701db8d6bd4b",
            "7aeaac9910454a68b333299408bf33d0",
            "114fd06c339142208d23c2f4e7ba6e87",
            "32965cd9783e44f5b25698f37096f436",
            "20d0ad4953a14298912d9196176d012c",
            "35b9cd8b19604d8ab0696859413c80d3",
            "0b632938eb014e01931094790a0611e7",
            "9a8601103c2b4873a2e46557f9208036",
            "5803635e018c4c4ca377d6360a516325",
            "463ff5ded9c340dfa01c5fb770b3c60c",
            "b832b4c3a33249b4881fab0464997b4b",
            "9a48e153ab9d4cd198e2692f5c159f70",
            "16b38915e6144a9fa27dd5320e8e373b",
            "d005a0fe71b7480fac0ad29ce5ea5eb6",
            "acd0977c2c4b4e09b922b8ef94b45e57",
            "f2accb12fe634c40a5441305bfa56764",
            "c20f112ec913444cb3fe799ff676574e",
            "3c8cae1c57d74b1cb453f9ba80eede1f",
            "f2c9d4cfc3a940de9a2a2c02e11326dc",
            "55be268d20874148812e4700720c84dd",
            "71d2c6684bfe42a384454bcdce8c08a2",
            "4e5597faf35e4bc080940371307f9ad2",
            "cbc3d3c631eb4a97af08b21fb2df6f10",
            "055933aeca194a42b6057dfadee322f5",
            "f729856608ee4bc89e3f1bb6dc9c3b7d",
            "160a9e6236ae45e89f9accd8b80a28f0",
            "dd37e2098e344b6fab84282f34502161",
            "ef4bd2457c1946db8eef01c7b030e0d5",
            "021fa0ff28094b27bd7907993f56dad6",
            "b1134dcda7d448a59bd61082997bb78f",
            "ca3cceb246b745b4a3efb9622bb92353",
            "1b715558dc994c3386220f934f74361d",
            "78e87ebf14f74323b74ba9ac500378c8",
            "1375a56975d74c1690be563ddd3f480b",
            "5f990f003a214b2c87ee1ce2034d7219",
            "6080746235ce4b8697a001433b8ecb3b",
            "9305172aa1324b7db10721cd5dd42a5f",
            "5be21b0c0f2044ef8fa3c269efd018fd",
            "ecaaede502564ab19237a03f5bf055c0",
            "a01659fdc06f426c81bdc03b3799351e",
            "cda9c90c22514c48a84094a811031d8d",
            "e7ed515df09340f59affd4c5f303f2b1",
            "5f632a282bfd4f8a84cc850cba7fd86c",
            "4ca00aae968a45bc84569a7401c45fc8",
            "ff1cc904a4a24b97bf890be9411d1a6f",
            "b48bcb67d0714902a1c1c1553a7d0d4b",
            "cfb75fd6a1f6453180b6f3785de0a7e9",
            "f7bc8452f92247e2a355e4e41df1d5a7",
            "5c44a542605d415f832e6eb7b2df9240",
            "ba34e51e6f3741988153c1ed15a81afb",
            "9c0f046416f146b2bde00f0c807e9eb8",
            "f882f285c24842918e21fb12d7ba62af",
            "ea9ecd838fad4498aa4036168cf56a64",
            "f5f5ee1ffd7e427da124d86244a3c2e6",
            "8e6e6203af7d4331970a626e4b727a72",
            "f9812e52fa1b465f9ca3274d64891268",
            "7bf78be77a5e4727aa6b303ee7d8fbfe",
            "d46638db0c644ecb9e59a3a151b92197",
            "b6fcd5222e5444468cc5411496b45200",
            "1abe14d6f8104050aa2d4ee8576f93e1",
            "62866682aab54574acca68de5deb8250",
            "d835bcb514a444fab0e9077d7b76f18d",
            "5425e4147450451db8342e3c49d89ef7",
            "a294e5d2bcd647c48d2fc36c2cb2b351",
            "c6adb99ea4c54c6bbc6cdd7484b74a07",
            "e0c470f57a704377982987f36a3a810a",
            "4994eb9321e046b7991ad4a09270fb16",
            "2b35c60a5b1948188e30e85ccf48edd3",
            "4a06ca9423704444be349acdbe0f663e",
            "e67fc05971dc4f24be5ef488debe93b4",
            "963d46fa45064d0ab1e1b325fa8f2582",
            "fa42d35b5e8e4b8290fc9c07c66c5d10",
            "854a7fb3610c45d9bd12697f110f03ea",
            "4ef516337d8048edbfbe6a401677e824",
            "5220c0a5ccb3429b991e70a9ac60b94c",
            "1dbbaff40e584619a370c1bc49becc43",
            "4f5bac643bb744149bdce500d7960b9f",
            "68f7bf83565447efade31facd02f0207",
            "e76233594c6242b2b77871dbfa6cae4e",
            "17755ee2e0644009adbb6d2a753f230e",
            "7b94941f4cb347f8980d021ca6ca32ca",
            "33ca57c7e24645dd9384dc99964893be",
            "ba72ac24de4d43388e9db2801a1d4b98",
            "e32c4f3d8a82442b9384a1182062022c",
            "50fd16adfc56491a94f04e6cafb561c3",
            "5a1a710325464b3ebfaa650e85a8107d",
            "dc93acfb5dea4970b3b35334af7b9091",
            "72b69e5bc9b54f64ab2824ab2d9c9baf",
            "325b6e7afe8a4f72ad96b46bc2a22e33",
            "1a16f52291934af299755fdad2003db1",
            "8ddf038913294c588aa7480646cb5ee0",
            "228118165d604b188363a65083cbaf34",
            "13f28c4247cd419a9de8d7ff7cfc24c9",
            "5fd67aca29054a0daec224a4262f70dc",
            "c4553fbdbbd74955b3c54662ca237abe",
            "3079ff69482b410ba7c5c0173b0ec84b",
            "cc01af7cb6294f129e9a804c289859ed",
            "6305164828cf4b2f9d45cfcff546e524",
            "66c844a410f8423e85f9e3baa3244aa4",
            "dc31ccf9958d40d8b4d2a5bdbf3aab0e",
            "7ecb6f1600b24572b04ecf584cdf55b3",
            "333c7ca95a7e4fe59398241e4cb8bd9d",
            "8eb994fba3f441c680790c5a214823b6",
            "554f400be0f54bb2aa5f859d89963049",
            "3657f28c53904bb188f600c40fb2218a",
            "3c5978a2a64146b6bb863b139accb459",
            "592a2d951cdb4926bcd4a556ae193ecc",
            "278edc522b31427197a7a8071ee15614",
            "cb44dcd6ede64499ae24cd55c7117347",
            "45b9b95455d54d40a49d09c2fa8425c2",
            "205eadc615a0475cba26a3144a47f404",
            "96260ce6b36646b7a20b3b39f71e88b2",
            "4748aae75a8c446c946d197f5ea51eaf",
            "54caff5a0d384ac5b0b3a62bd7b2e01c",
            "b795a49c996242d99c19d74356d939f7",
            "b362fb6e8efa4468b5ac390d2c55b7f5",
            "174f14eaa49646fc9cb4efd6ca367bc2",
            "7b25de43fce74efa93f69e9b3f010836",
            "52e4534c354d4457983eca297d8b80a4",
            "28bdbc4e42714695854b1da737be0cb7",
            "b126099dfe694bac8b06607368ebaa11",
            "53909bc128474b17a8939b630f99d425",
            "3de67855220d4144a4d3178373f4298c",
            "369002df02d34baa86e4a54703add8bb",
            "38633bb65cce4a558e1784c24932a649",
            "3a4a5e53e7bf4fc18ce6a9f030ae2359",
            "8889f4ef1e0c40bdaf8ef04efe8dee00",
            "aefdffbfa36b4818894b0745e278ebbf",
            "70a642e58311453b8661775821e320f6",
            "08e5087d09564a2284ff5ae10bbdb320",
            "b446fed3de4c47b7b691c5de54f04fc9",
            "d739e415f45640c3b8eabe0b83f039c5",
            "ea5149b8541c4ed29de7351eed581fba",
            "d8ec40440c31496c8350db34557d517d",
            "1a113fd2a75b496d9e0690dfb0789cd9",
            "d7bcf17fc1a64d58a44d80b4db812157",
            "51fc5eb0ee594283a2336fa4b79ae4ce",
            "0b86afdce9c747f4824d1847acd3e4cb",
            "5f3b79b0436d4d179ac3b7ea343eae87",
            "280574f376a74871ba468801effe4826",
            "5a76aad62efb4079880300ff9128ae5a",
            "47b059786d95445dba1266673d1cfc0c",
            "f10a196c48c0443885fd505bd92a7f4f",
            "dfd00bbe62f448beb184eeaf3311a5c1",
            "65155c734fdd4ffdbc250d3c8198341f",
            "21da27e277024eb58927ae673cba23a0",
            "3d91844700464202afdc6dbf4bea2f44",
            "84ba3653130a4de0b3fd2570a6af0b74",
            "a19654e1db1445c293652e7cbf3616ee",
            "7519460bdbd4419a86f29d5693bc19b6",
            "9a1749916117490ebfb6e4e3ceed867c",
            "afc837db30754b11ae45aa2a92b11c93",
            "e13f65dc35924ada9ff1e3095884f010",
            "9b6231837fcc4f28a730f11513dfcf31",
            "46ca58a77cb745e0b8265ef52c9a4446",
            "375ef3a29004495ba74217d473136c11",
            "b96950edafeb4777b4a1f5e0b648b8a6",
            "a86ffe5ae57b44b589115edc4c00211f",
            "8b32d63932ac431797fd82801a21f843",
            "17e1b85ba11040d6829bdef32301d316",
            "f27407c560b24c9399832c714af27fc5",
            "c5e5061cb31e4a3b87a859e93e8f754f",
            "66c3deef53d24300acbf62b6e34f30ae",
            "9748eba05688496a8a88b3217954e660",
            "27c82dd055464fe0afca44a318fe9b52",
            "bcdb023406a240c48958ca168f5bfc4b",
            "612cbd91b0e149b7980f477bc5e4e86c",
            "cee15203ecf144aea98a9615dda04dd7",
            "8ed1bf4ad29b4cba9a88b4ab295f4ee9",
            "2d54a34537e349e986e9f94b715121d0",
            "d1f1e0b0edf346228d3d0672c1aca62f",
            "910a4809cdd0473796880c6ef8bc9854",
            "dfb7e7008fc94c4fab35a7dd6aead100",
            "31b47db2d36040b6bace82543a4abe7d",
            "864c5a3ad90d47a682ca946aadd48881",
            "3e82d426b7b64954bbc96ac7c318289a",
            "d2282340de914082bdd98ebe53a34887",
            "adcc2a4c4f0c4e0f9dfcea1a0c681f32",
            "b0ce43e9f3e24fedb599cee92f111fcb",
            "a9a116190e4148dbaa7eb15d3452ab2e",
            "a553fd1745ad45a8af27363668805cf2",
            "6d29f176105c44f29ec9aa5e547c1d4e",
            "5e7c99f0cfaa4ca38f4fa66de322c0da",
            "e5752ccf57754211ad9f26dbba572ab0",
            "dfe7dcdc2c764037936889f83b666014",
            "6648011aa0af4a77892f8b4fbf55ee10",
            "ff853c06f2054601b847fda0d6d3f688",
            "ee4a4a06afe244f39091744b593d8def",
            "2840d54399154a4295febde1d9001658",
            "ab48800fea0a4c8dbd4a6daa06e53550",
            "25de86944ead447e9bebd5236e5ec192",
            "cf1175ee117c452d8e307e2278839716",
            "9ec478a134b14a5e8bf5cb9a70413cb6",
            "72c361f30fff466e97b7f8e01367abd5",
            "389d0386512b4fb6aacf5eba9e078374",
            "03dfdb8c26c04766b8b975088339c714",
            "f8ad1a03fb2846f7a68b98958ff2f595",
            "a6acc118301347ceb239fef40797bb66",
            "021d12e4dbb24152a5ff1cf19b362e0c",
            "b372616dfe6c44c18cd5cae021cdbc60",
            "b298b7c0507141749c804e12a8f78694",
            "5dc205c1baba443797e39a5767a18891",
            "0efda6967c534e67a670b36d8fe462bb",
            "2fd742c61b14418c958586349b04b9b9",
            "a20b16435b264fda8dc315992343df14",
            "a4ddf608bedf49ecb7540c4d58c6dafb",
            "781c15fbe80844aa85ac4a6db9db959b",
            "77c07c049f2c41d88ed9bc597f5106ce",
            "f9fb041d73da4cb2b2d5a2df393cc06f",
            "d7426d7e0e9e4fec8e9409fa3f161692",
            "54a346326f5b47e3bac7a447a7c23e9b",
            "84b37f72e260437bbae7fe6cc96ccb09",
            "d72b77fc07e247f18552c8d2670634be",
            "54bc265f47534c64a487762ea807258b",
            "f6384a6ec5f0457285b810beebf342f1",
            "75e975db8dfe4570a4164c3559e7ea47",
            "6e3a2653c73a438883fa7da451f0c79e",
            "701dcae43cf1467ba0d23a84aa575842",
            "f0b8adfa508f4e34a983fc2bc4c4b912",
            "f84a7841ca624ac1ad0b29fdd0d19163",
            "123e1d16254b477aa625182c30bb4ebc",
            "123b767a02274bbaa214c8258af1bc7e",
            "250b65f1bbfb418dbf7ad73a935dd55e",
            "7368e58e53284c43a3f8a3eebecaed5e",
            "f5e245a753054563ba75af3b02bc9652",
            "c4ce371faedd494eab93d6dfc59ca30d",
            "62af6c1d41ed44d39534b8b61ae74f0f",
            "b97b35377ca74307b414a43e26e4372e",
            "8e037f0cdfbe46b5a4d0fbe2086149f1",
            "7b8179bf98af4b87969c545dd78610c2",
            "ae0d2dcb292d43878e6719add640f49b",
            "2ba991aaf2d943689b753712894cb74b",
            "741d4180ec444ee4ae3ddf479fc6e92c",
            "eb4d3e76517a44ee996a436b5379ce04",
            "322d5487c1d4475aaa8ba6164a9aec0a",
            "7ca72284b49343db95f2b0a72b76902d",
            "beb01161f5e041a5ae89de419ff2aa12",
            "f1d8ee0cbc4d4b378f2796c1a95a0c0a",
            "384acd8ad36343a5b9ad8ab9166f78e3",
            "4bb22a9d09694c888ce64c07d672d95f",
            "e30b75817c714586b94889a782c8b48c",
            "608fa1c9433a47f4bbeac866e438b629",
            "f04a78d9a52d4a20966deaba801f0b60",
            "1cde5f334cda450baf644e0e969c0b36",
            "fa1b2b2bf5d74e7082c8ee7f45c925c7",
            "bd8c76e84c504dad808d4756846f9415",
            "4ff8a2f1993242fca43e0611f1622ff0",
            "b085d12e55174664bea389712a8d08e2",
            "8b2a130dbfd040799122ee151ea21d3b",
            "07c3fc0f71ef42d095e3c3ff56b0b9e1",
            "69b36e1844c94047884f1e34f36bc02e",
            "3937be3bc88f437f9d762df62adbe500",
            "b196122a07dd4e1ab14df31cb8bc9445",
            "894c220dd1dd4ade9018e26c9e2e967e",
            "44fe94d3beea48829703639c0d6ef271",
            "8575adf3ee0a4c78ad1a282fde71c3e5",
            "c2fb76b81bb84d6290d6fa9b2056e49a",
            "c282608036da46ebadfe03cb82b76367",
            "97c3f0d0eb5847d7a3899bd1165df540",
            "f7147f79526f423ebae897fa6abb8211",
            "4c2b190221b44b169a21fa0b810e365f",
            "918d0800a3f64baaa320a9d3357f7fc3",
            "1a4c489967a541129ac3707ccf98162f",
            "fafdebb8474d42338d28dcb41d598465",
            "98e9d0560e5043408949950447513009",
            "f303c4bb993846589a705203e47a68ec",
            "927f4d99d5974256bacd2cbeb4fdc559",
            "8dfc40c6296f45c3a197352b3316ad0d",
            "d20995818fcb4baf9a5535aed820cc5b",
            "8429759a65cf4d6b93c58b0c20ca5b28",
            "f40d4396b9f846aeb6ab009676112b07",
            "a63e56a444fe408a9e82e9226392ec1a",
            "9541ba3e8c4d4bce93ca2b637eb8e666",
            "06f6578b1e3f4af991c13da459b2043a",
            "cd24325c3a2442a09de7e5c1c0416a2d",
            "66f60fd212c34cd79047ceb58073bd32",
            "9f0e13517b8d497fbca3edfe16f02d46",
            "86d4a6284589469084305457b284159b",
            "5dc115d4f2664951b5e9ff07376d556f",
            "b73c00399e254f5eb57dd7582923dec8",
            "837ac219e5fd48f896f87da9d7169b9b",
            "06be59f930b8470a80f002aaa3f7e9a3",
            "3e88672f113e4150a2ee41739290cce2",
            "2dc26ac768884f0ba089e2314a614f06",
            "96be2d41ed50449692f56fabcc5e8380",
            "d1363771673f438eafef8fc4c24d08ca",
            "d923a2e4777f438f92558d486aa3c8d6",
            "2dbf39e3407d4fc28faf941055ada459",
            "af8885410d1549419286db144e7f360a",
            "ae43fc1659264ca5b99e4f108f898b76",
            "2fef6954aa9346a79b216e42f44a1b0d",
            "3e5364a02a0844a7bb53384d72ce1f22",
            "450f3bf00b5a46338e8574f514fc81f4",
            "0f5afb6304fa43ad8a329bcc599df537",
            "780711bcfe114846a80cd71f2f0f81b1",
            "3acea200b89f43529c27f5cbeeee2ac4",
            "b16c97dc41764e85bf45d6b519d1dc84",
            "0961d1cd73f84c028c882670ffd9a460",
            "1389472a26fa40d198b3673c3096f4cb",
            "cdbda89135964d95a09f1e480573eb4d",
            "37717401424d4cb380e3395a64313a09",
            "ba2082225a7048df851ea73c796e2eba",
            "cfbc315c201c45c8889bddc6aca176d7",
            "1259c8b46e6b4f339d6b59ad65eb4a5e",
            "36efaf5d242b41a689a379ebaead9d21",
            "8abc0905a4b948dd8ffac8441b19f719",
            "5d190a4d196944ff8f281c8bf75acfe3",
            "959ed7210a6948a5aa27f7db742b8d25",
            "1ac1fd3c623c4fe29b3ee5a0e1f5d671",
            "cc4874ab8f90416a940b9e7066d2764d",
            "ed644284831148eaa536a1788a135b53",
            "12516abad53a4b4fb37b1afa2013c7b3",
            "ad8ee1fd016e4cad8625ec71f54e49ca",
            "134aec989acc4c92bfe2a9e1e856f38c",
            "dada831ab43d43fb885b9c4efa2c9f6e",
            "a1fd637535da49f595b485017b95dfee",
            "994abe6bc8dc42e38fd3f44fc1a0f439",
            "214ec2081c8f4474b58f46883b5b23cb",
            "cf5763e1b27d473ba0e9809cb30e5c93",
            "07022b44c6bd4e1380ea13880f341458",
            "8a76ba4df9744d6e9ce9ec0f5f480f4e",
            "deca163bac1c4484a6071452bfca5709",
            "368951d7b95e4673bbdd92858c13d9fb",
            "c211431871ff44ca8537ee3cd8262769",
            "c4f4212a1cd940f19281372c6f11292f",
            "ce5870ed34844a64bb4f1fcb77d2098b",
            "9c9f643eb0f640eea9ea51fe70a7cacf",
            "0aa75a7b0f17494792c19e17cddc26b4",
            "9555d40a33884f3394500a30ca8b0270",
            "bfe043ee952c44a8afa611381cbc05da",
            "9e01038418a94c30828023452c8a9245",
            "6fd30d37469641fe9933f66dac6ee51f",
            "5f38da6a6cc643258dc877f2fcdae983",
            "6f90ab9500724a6c8500366bf4d1d4c0",
            "67fc5a9623a641619644a2e4234c4993",
            "0a015d5668cc49628d8253d37e3efc2e",
            "e79d036d2a634c889b62e95d10fdd2d7",
            "c2527b8949b5424a8bea06b275d67509",
            "a6bfd8498c6647d2ace8e7978e03f057",
            "f85b3addcdfb4943a7073168e017d20a",
            "d74f189784d64f2da4379573746fc0ce",
            "a151994c22ec4abfba6624ef71a4fbac",
            "43f6897aa5974177a92a621d72a6fea3",
            "b4471503ca0a4b6799ccdfa5778a0dcd",
            "dc92059e31074eb9a2ce50d2e8750081",
            "8049e28bbf9e40b78429561522c3fdc3"
          ]
        },
        "id": "6O-o5sA-SO7-",
        "outputId": "d9cfcb05-bbb0-43e7-e865-7f27e92fbce6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model: meta-llama/Llama-3.3-70B-Instruct\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b982d4610ec4443691265d6c4a55edfa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/879 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b40361687e1f4f1cb61d6ac4e7572e92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/59.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb8d27668e4e4649bac9f51e96ab6db0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b54e8052e9f441b9e3c2446afabd692",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c77b231995594213a661a05f3ab2ef05",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00008-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5255660e24bf4fdebdd1d4e18836bd5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00007-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40c7676bf71340b3a6b14cfac4d03a9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00004-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35b9cd8b19604d8ab0696859413c80d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00030.safetensors:   0%|          | 0.00/4.58G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c20f112ec913444cb3fe799ff676574e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef4bd2457c1946db8eef01c7b030e0d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00005-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ecaaede502564ab19237a03f5bf055c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00006-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba34e51e6f3741988153c1ed15a81afb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00009-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62866682aab54574acca68de5deb8250",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00010-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa42d35b5e8e4b8290fc9c07c66c5d10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00011-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba72ac24de4d43388e9db2801a1d4b98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00012-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fd67aca29054a0daec224a4262f70dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00013-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3657f28c53904bb188f600c40fb2218a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00014-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b362fb6e8efa4468b5ac390d2c55b7f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00015-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8889f4ef1e0c40bdaf8ef04efe8dee00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00016-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b86afdce9c747f4824d1847acd3e4cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00017-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a19654e1db1445c293652e7cbf3616ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00018-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17e1b85ba11040d6829bdef32301d316",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00019-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1f1e0b0edf346228d3d0672c1aca62f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00020-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d29f176105c44f29ec9aa5e547c1d4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00021-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ec478a134b14a5e8bf5cb9a70413cb6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00022-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fd742c61b14418c958586349b04b9b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00023-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6384a6ec5f0457285b810beebf342f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00024-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4ce371faedd494eab93d6dfc59ca30d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00025-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "beb01161f5e041a5ae89de419ff2aa12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00026-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b085d12e55174664bea389712a8d08e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00027-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97c3f0d0eb5847d7a3899bd1165df540",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00028-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8429759a65cf4d6b93c58b0c20ca5b28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00029-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "837ac219e5fd48f896f87da9d7169b9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00030-of-00030.safetensors:   0%|          | 0.00/2.10G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e5364a02a0844a7bb53384d72ce1f22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfbc315c201c45c8889bddc6aca176d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "134aec989acc4c92bfe2a9e1e856f38c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4f4212a1cd940f19281372c6f11292f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a015d5668cc49628d8253d37e3efc2e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/68.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading QA file: ./data/annotated/QA_pairs_1.csv\n",
            "Generating answers...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "run_baseline(\"meta-llama/Llama-3.3-70B-Instruct\", \"./output/llama33_70B_baseline.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nhtVcobZQ3S"
      },
      "source": [
        "Goocle Colab Pro A100 can't run llama3.3 70B, maybe Pro+ can. IDK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM95JNvV2Fo-"
      },
      "source": [
        "### gemini-2.0-flash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSwZmBV3YMI9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from google import genai\n",
        "import time\n",
        "from google import genai\n",
        "\n",
        "import time\n",
        "from google import genai\n",
        "\n",
        "def call_gemini_with_interval(client, model, contents, config, interval=20, retries=3, backoff_factor=2):\n",
        "    \"\"\"\n",
        "    Call Google Gemini API with a fixed interval between requests and retry logic for handling errors.\n",
        "\n",
        "    Args:\n",
        "        client (genai.Client): The Google Gemini client.\n",
        "        model (str): The model name (e.g., \"gemini-2.0-flash\").\n",
        "        contents (str): The input prompt or question.\n",
        "        config (dict): Configuration for the API call (e.g., tools, temperature, etc.).\n",
        "        interval (int): Time in seconds to wait between API requests.\n",
        "        retries (int): Number of retries for handling quota exhaustion or other errors.\n",
        "        backoff_factor (int): Factor for exponential backoff in case of retries.\n",
        "\n",
        "    Returns:\n",
        "        response: The response from the Google Gemini API.\n",
        "    \"\"\"\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            # Send the API request\n",
        "            response = client.models.generate_content(\n",
        "                model=model,\n",
        "                contents=contents,\n",
        "                config=config,\n",
        "            )\n",
        "            print(f\"Request succeeded. Waiting {interval} seconds before the next request...\")\n",
        "            time.sleep(interval)  # Wait for the specified interval\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            if \"RESOURCE_EXHAUSTED\" in str(e):\n",
        "                print(f\"Quota exceeded. Retrying in {backoff_factor ** attempt} seconds...\")\n",
        "                time.sleep(backoff_factor ** attempt)\n",
        "            else:\n",
        "                raise e\n",
        "    raise Exception(\"Max retries exceeded. Quota still exhausted.\")\n",
        "\n",
        "\n",
        "\n",
        "def run_gemini_baseline(api_key, output_file, qa_file=\"./data/annotated/QA_pairs_1.csv\", sample_size=100):\n",
        "    \"\"\"\n",
        "    Generate QA baseline answers using Google's Gemini model and save the results to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        api_key (str): API key for accessing Google's Gemini model.\n",
        "        output_file (str): Path to save the generated answers.\n",
        "        qa_file (str): Path to the QA annotation test set CSV file.\n",
        "        sample_size (int): Number of QA pairs to sample for evaluation.\n",
        "    \"\"\"\n",
        "    # Initialize the Gemini client\n",
        "    client = genai.Client(api_key=api_key)\n",
        "\n",
        "    # Load QA annotation test set\n",
        "    print(f\"Loading QA file: {qa_file}\")\n",
        "    # Randomly sample QA pairs\n",
        "    random.seed(42)\n",
        "    qa_df = pd.read_csv(qa_file)\n",
        "    qa_df = qa_df.sample(sample_size, random_state=221)\n",
        "    sample_doc_ids = qa_df[\"Doc_id\"].tolist()\n",
        "    sample_questions = qa_df[\"Question\"].tolist()\n",
        "    sample_answers = qa_df[\"Reference_Answers\"].tolist()\n",
        "\n",
        "    # Define the prompt template\n",
        "    template = \"\"\"\n",
        "    You are an expert assistant answering factual questions about various aspects of Pittsburgh or Carnegie Mellon University (CMU), including history, policy, culture, events, and more.\n",
        "    If you do not know the answer, just say \"I don't know.\"\n",
        "\n",
        "    Important Instructions:\n",
        "    - Answer concisely without repeating the question.\n",
        "    - Do **not** use complete sentences. Provide only the word, name, date, or phrase that directly answers the question. For example, given the question \"When was Carnegie Mellon University founded?\", you should only answer \"1900\".\n",
        "\n",
        "    Examples:\n",
        "    Question: Who is Pittsburgh named after?\n",
        "    Answer: William Pitt\n",
        "    Question: What famous machine learning venue had its first conference in Pittsburgh in 1980?\n",
        "    Answer: ICML\n",
        "    Question: What musical artist is performing at PPG Arena on October 13?\n",
        "    Answer: Billie Eilish\n",
        "\n",
        "    Question: {question} \\n\\n\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate answers\n",
        "    print(\"Generating answers using Google Gemini...\")\n",
        "    generated_answers = []\n",
        "    for question in tqdm(sample_questions):\n",
        "        full_prompt = template.format(question=question)\n",
        "        response = call_gemini_with_interval(\n",
        "          client,\n",
        "          model=\"gemini-2.0-flash-thinking-exp-01-21\",\n",
        "          contents=full_prompt,\n",
        "          config={}, # {\"tools\": [{\"google_search\": {}}]},\n",
        "          interval=4,  # Wait 4 seconds between requests\n",
        "          retries=3,    # Retry up to 3 times if quota is exceeded\n",
        "          backoff_factor=2  # Exponential backoff for retries\n",
        "        )\n",
        "\n",
        "        # Extract the generated answer\n",
        "        generated_answers.append(response.text)\n",
        "\n",
        "    # Save results to a CSV file\n",
        "    results_df = pd.DataFrame({\n",
        "        \"Doc_id\": sample_doc_ids,\n",
        "        \"Question\": sample_questions,\n",
        "        \"Reference_Answers\": sample_answers,\n",
        "        \"Generated_Answer\": generated_answers,\n",
        "    })\n",
        "    results_df.to_csv(output_file, index=False)\n",
        "    print(f\"Results saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX9ZvAxvhA7P",
        "outputId": "b5fa3f4a-6728-4fbc-d05e-c1c79a70a944"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading QA file: ./data/annotated/QA_pairs_1.csv\n",
            "Generating answers using Google Gemini...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 1/100 [00:05<09:48,  5.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 2/100 [00:11<09:01,  5.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 3/100 [00:16<08:32,  5.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 4/100 [00:22<09:16,  5.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 5/100 [00:28<08:52,  5.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 6/100 [00:35<09:36,  6.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 7/100 [00:39<08:47,  5.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 8/100 [00:45<08:39,  5.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 9/100 [00:50<08:11,  5.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 10/100 [00:55<08:04,  5.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 11/100 [01:01<08:08,  5.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 12/100 [01:06<08:03,  5.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 13/100 [01:13<08:22,  5.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 14/100 [01:21<09:23,  6.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 15/100 [01:31<10:34,  7.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 16/100 [01:37<09:54,  7.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 17/100 [01:42<08:54,  6.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 18/100 [01:47<08:17,  6.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 19/100 [01:52<07:43,  5.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 20/100 [01:58<07:47,  5.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 21/100 [02:04<07:43,  5.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 22/100 [02:10<07:37,  5.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 23/100 [02:15<07:12,  5.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 24/100 [02:20<06:57,  5.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 25/100 [02:25<06:46,  5.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 26/100 [02:30<06:30,  5.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 27/100 [02:35<06:13,  5.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 28/100 [02:40<06:01,  5.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 29/100 [02:48<06:53,  5.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 30/100 [02:54<06:53,  5.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 31/100 [02:59<06:42,  5.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 32/100 [03:05<06:26,  5.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 33/100 [03:13<07:19,  6.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 34/100 [03:18<06:38,  6.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 35/100 [03:23<06:19,  5.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 36/100 [03:31<06:39,  6.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 37/100 [03:38<06:55,  6.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 38/100 [03:43<06:12,  6.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 39/100 [03:48<05:49,  5.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 40/100 [03:53<05:27,  5.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 41/100 [03:59<05:37,  5.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 42/100 [04:05<05:43,  5.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 43/100 [04:10<05:15,  5.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 44/100 [04:16<05:15,  5.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 45/100 [04:21<05:06,  5.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 46/100 [04:47<10:29, 11.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 47/100 [04:55<09:14, 10.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 48/100 [05:00<07:38,  8.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 49/100 [05:13<08:32, 10.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 50/100 [05:18<07:03,  8.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 51/100 [05:23<06:06,  7.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 52/100 [05:29<05:38,  7.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 53/100 [05:34<05:02,  6.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 54/100 [05:42<05:27,  7.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 55/100 [05:51<05:43,  7.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 56/100 [06:02<06:13,  8.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 57/100 [06:08<05:32,  7.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 58/100 [06:13<04:52,  6.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 59/100 [06:18<04:24,  6.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 60/100 [06:23<04:01,  6.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 61/100 [06:29<03:50,  5.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 62/100 [06:37<04:08,  6.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 63/100 [06:46<04:25,  7.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 64/100 [06:51<04:02,  6.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 65/100 [07:00<04:15,  7.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 66/100 [07:05<03:47,  6.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 67/100 [07:11<03:32,  6.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 68/100 [07:16<03:12,  6.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 69/100 [07:22<03:03,  5.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 70/100 [07:27<02:49,  5.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 71/100 [07:32<02:36,  5.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 72/100 [07:37<02:29,  5.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 73/100 [07:42<02:25,  5.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 74/100 [07:48<02:20,  5.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 75/100 [07:53<02:11,  5.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 76/100 [07:58<02:04,  5.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 77/100 [08:04<02:07,  5.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 78/100 [08:09<01:56,  5.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 79/100 [08:17<02:08,  6.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 80/100 [08:22<01:57,  5.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 81/100 [08:28<01:49,  5.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 82/100 [08:32<01:38,  5.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 83/100 [08:37<01:29,  5.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 84%|████████▍ | 84/100 [08:43<01:28,  5.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 85%|████████▌ | 85/100 [08:53<01:40,  6.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 86%|████████▌ | 86/100 [08:58<01:26,  6.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 87/100 [09:02<01:14,  5.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 88/100 [09:09<01:10,  5.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 89%|████████▉ | 89/100 [09:15<01:04,  5.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 90/100 [09:23<01:05,  6.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 91%|█████████ | 91/100 [09:29<00:58,  6.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 92/100 [09:35<00:50,  6.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 93/100 [09:46<00:53,  7.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▍| 94/100 [09:50<00:40,  6.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▌| 95/100 [09:55<00:30,  6.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 96/100 [10:00<00:23,  5.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 97%|█████████▋| 97/100 [10:07<00:18,  6.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 98/100 [10:12<00:11,  5.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 99%|█████████▉| 99/100 [10:17<00:05,  5.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [10:28<00:00,  6.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to ./output/gemini_2_flash_thinking_baseline.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "api_key = \"your gemini API key\"\n",
        "output_file = \"./output/gemini_2_flash_thinking_baseline.csv\"\n",
        "qa_file = \"./data/annotated/QA_pairs_1.csv\"\n",
        "sample_size = 100\n",
        "\n",
        "run_gemini_baseline(api_key, output_file, qa_file, sample_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEUtdb4riyrA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from google import genai\n",
        "def call_gemini_with_interval(client, model, contents, config, interval=20, retries=3, backoff_factor=2):\n",
        "    \"\"\"\n",
        "    Call Google Gemini API with a fixed interval between requests and retry logic for handling errors.\n",
        "\n",
        "    Args:\n",
        "        client (genai.Client): The Google Gemini client.\n",
        "        model (str): The model name (e.g., \"gemini-2.0-flash\").\n",
        "        contents (str): The input prompt or question.\n",
        "        config (dict): Configuration for the API call (e.g., tools, temperature, etc.).\n",
        "        interval (int): Time in seconds to wait between API requests.\n",
        "        retries (int): Number of retries for handling quota exhaustion or other errors.\n",
        "        backoff_factor (int): Factor for exponential backoff in case of retries.\n",
        "\n",
        "    Returns:\n",
        "        response: The response from the Google Gemini API.\n",
        "    \"\"\"\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            # Send the API request\n",
        "            response = client.models.generate_content(\n",
        "                model=model,\n",
        "                contents=contents,\n",
        "                config=config,\n",
        "            )\n",
        "            print(f\"Request succeeded. Waiting {interval} seconds before the next request...\")\n",
        "            time.sleep(interval)  # Wait for the specified interval\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            if \"RESOURCE_EXHAUSTED\" in str(e):\n",
        "                print(f\"Quota exceeded. Retrying in {backoff_factor ** attempt} seconds...\")\n",
        "                time.sleep(backoff_factor ** attempt)\n",
        "            else:\n",
        "                raise e\n",
        "    raise Exception(\"Max retries exceeded. Quota still exhausted.\")\n",
        "\n",
        "\n",
        "\n",
        "def run_gemini_baseline_with_search(api_key, output_file, qa_file=\"./data/annotated/QA_pairs_1.csv\", sample_size=100):\n",
        "    \"\"\"\n",
        "    Generate QA baseline answers using Google's Gemini model with Google Search grounding and save the results to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        api_key (str): API key for accessing Google's Gemini model.\n",
        "        output_file (str): Path to save the generated answers.\n",
        "        qa_file (str): Path to the QA annotation test set CSV file.\n",
        "        sample_size (int): Number of QA pairs to sample for evaluation.\n",
        "    \"\"\"\n",
        "    # Initialize the Gemini client\n",
        "    client = genai.Client(api_key=api_key)\n",
        "\n",
        "    # Load QA annotation test set\n",
        "    print(f\"Loading QA file: {qa_file}\")\n",
        "    # Randomly sample QA pairs\n",
        "    random.seed(42)\n",
        "    qa_df = pd.read_csv(qa_file)\n",
        "    qa_df = qa_df.sample(sample_size, random_state=221)\n",
        "    sample_doc_ids = qa_df[\"Doc_id\"].tolist()\n",
        "    sample_questions = qa_df[\"Question\"].tolist()\n",
        "    sample_answers = qa_df[\"Reference_Answers\"].tolist()\n",
        "\n",
        "    # Define the prompt template\n",
        "    template = \"\"\"\n",
        "    You are an expert assistant answering factual questions about various aspects of Pittsburgh or Carnegie Mellon University (CMU), including history, policy, culture, events, and more.\n",
        "    If you do not know the answer, just say \"I don't know.\"\n",
        "\n",
        "    Important Instructions:\n",
        "    - Answer concisely without repeating the question.\n",
        "    - Do **not** use complete sentences. Provide only the word, name, date, or phrase that directly answers the question. For example, given the question \"When was Carnegie Mellon University founded?\", you should only answer \"1900\".\n",
        "\n",
        "    Examples:\n",
        "    Question: Who is Pittsburgh named after?\n",
        "    Answer: William Pitt\n",
        "    Question: What famous machine learning venue had its first conference in Pittsburgh in 1980?\n",
        "    Answer: ICML\n",
        "    Question: What musical artist is performing at PPG Arena on October 13?\n",
        "    Answer: Billie Eilish\n",
        "\n",
        "    Question: {question} \\n\\n\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate answers\n",
        "    print(\"Generating answers using Google Gemini with Google Search grounding...\")\n",
        "    generated_answers = []\n",
        "    search_queries = []\n",
        "    search_pages = []\n",
        "\n",
        "    for question in tqdm(sample_questions):\n",
        "        full_prompt = template.format(question=question)\n",
        "        response = call_gemini_with_interval(\n",
        "          client,\n",
        "          model=\"gemini-2.0-flash-thinking-exp-01-21\",\n",
        "          contents=full_prompt,\n",
        "          config={\"tools\": [{\"google_search\": {}}]}, # Enable Google Search grounding\n",
        "          interval=4,  # Wait 4 seconds between requests\n",
        "          retries=3,    # Retry up to 3 times if quota is exceeded\n",
        "          backoff_factor=2  # Exponential backoff for retries\n",
        "        )\n",
        "\n",
        "        # Extract the generated answer\n",
        "        generated_answers.append(response.text)\n",
        "\n",
        "    # Save results to a CSV file\n",
        "    results_df = pd.DataFrame({\n",
        "        \"Doc_id\": sample_doc_ids,\n",
        "        \"Question\": sample_questions,\n",
        "        \"Reference_Answers\": sample_answers,\n",
        "        \"Generated_Answer\": generated_answers\n",
        "    })\n",
        "    results_df.to_csv(output_file, index=False)\n",
        "    print(f\"Results saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxZlrFuVi6ij",
        "outputId": "9a0f599f-c4ee-46fe-ca40-1d3422445193"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading QA file: ./data/annotated/QA_pairs_1.csv\n",
            "Generating answers using Google Gemini with Google Search grounding...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 1/100 [00:06<10:48,  6.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 2/100 [00:11<08:45,  5.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 3/100 [00:15<08:05,  5.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 4/100 [00:21<08:15,  5.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 5/100 [00:25<07:50,  4.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 6/100 [00:30<07:33,  4.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 7/100 [00:34<07:21,  4.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 8/100 [00:39<07:12,  4.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 9/100 [00:43<07:03,  4.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 10/100 [00:48<06:56,  4.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 11/100 [00:53<07:11,  4.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 12/100 [00:59<07:23,  5.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 13/100 [01:04<07:21,  5.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 14/100 [01:09<07:02,  4.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 15/100 [01:13<06:46,  4.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 16/100 [01:18<06:36,  4.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 17/100 [01:23<06:54,  4.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 18/100 [01:28<06:55,  5.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 19/100 [01:33<06:38,  4.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 20/100 [01:38<06:42,  5.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 21/100 [01:44<06:42,  5.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 22/100 [01:48<06:23,  4.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 23/100 [01:53<06:10,  4.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 24/100 [01:57<05:59,  4.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 25/100 [02:02<06:06,  4.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 26/100 [02:08<06:11,  5.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 27/100 [02:12<05:55,  4.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 28/100 [02:18<06:02,  5.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 29/100 [02:23<06:10,  5.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 30/100 [02:29<06:11,  5.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 31/100 [02:34<06:06,  5.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 32/100 [02:39<05:45,  5.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 33/100 [02:44<05:46,  5.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 34/100 [02:50<05:46,  5.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 35/100 [02:54<05:27,  5.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 36/100 [03:00<05:34,  5.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 37/100 [03:05<05:30,  5.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 38/100 [03:11<05:32,  5.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 39/100 [03:16<05:28,  5.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 40/100 [03:21<05:07,  5.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 41/100 [03:27<05:26,  5.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 42/100 [03:32<05:17,  5.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 43/100 [03:37<04:56,  5.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 44/100 [03:42<04:54,  5.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 45/100 [03:47<04:38,  5.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 46/100 [03:52<04:38,  5.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 47/100 [03:57<04:23,  4.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 48/100 [04:02<04:25,  5.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 49/100 [04:07<04:12,  4.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 50/100 [04:11<04:00,  4.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 51/100 [04:17<04:01,  4.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 52/100 [04:22<04:03,  5.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 53/100 [04:27<03:51,  4.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 54/100 [04:32<03:55,  5.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 55/100 [04:38<03:55,  5.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 56/100 [04:42<03:40,  5.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 57/100 [04:47<03:30,  4.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 58/100 [04:52<03:30,  5.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 59/100 [04:57<03:20,  4.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 60/100 [05:02<03:21,  5.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 61/100 [05:07<03:11,  4.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 62/100 [05:11<03:03,  4.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 63/100 [05:17<03:03,  4.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 64/100 [05:21<02:53,  4.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 65/100 [05:27<03:00,  5.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 66/100 [05:32<02:49,  4.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 67/100 [05:36<02:39,  4.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 68/100 [05:42<02:40,  5.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 69/100 [05:46<02:31,  4.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 70/100 [05:52<02:35,  5.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 71/100 [05:58<02:33,  5.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 72/100 [06:03<02:28,  5.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 73/100 [06:08<02:25,  5.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 74/100 [06:14<02:18,  5.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 75/100 [06:18<02:07,  5.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 76/100 [06:24<02:04,  5.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 77/100 [06:28<01:54,  4.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 78/100 [06:34<01:52,  5.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 79/100 [06:39<01:49,  5.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 80/100 [06:44<01:45,  5.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 81/100 [06:49<01:35,  5.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 82/100 [06:54<01:32,  5.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 83/100 [06:59<01:24,  4.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 84%|████████▍ | 84/100 [07:04<01:21,  5.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 85%|████████▌ | 85/100 [07:09<01:13,  4.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 86%|████████▌ | 86/100 [07:13<01:07,  4.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 87/100 [07:18<01:01,  4.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 88/100 [07:22<00:55,  4.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 89%|████████▉ | 89/100 [07:27<00:50,  4.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 90/100 [07:32<00:49,  4.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 91%|█████████ | 91/100 [07:37<00:43,  4.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 92/100 [07:43<00:40,  5.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 93/100 [07:47<00:34,  4.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▍| 94/100 [07:52<00:29,  4.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▌| 95/100 [07:58<00:25,  5.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 96/100 [08:02<00:19,  4.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 97%|█████████▋| 97/100 [08:07<00:14,  4.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 98/100 [08:11<00:09,  4.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 99%|█████████▉| 99/100 [08:16<00:04,  4.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [08:21<00:00,  5.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to ./output/gemini_baseline_with_search.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "api_key = \"your gemini API key\"\n",
        "output_file = \"./output/gemini_baseline_with_search.csv\"\n",
        "qa_file = \"./data/annotated/QA_pairs_1.csv\"\n",
        "sample_size = 100\n",
        "\n",
        "run_gemini_baseline_with_search(api_key, output_file, qa_file, sample_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add Search to Google Gemini didn't improve the accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### gemini-2.0-flash-thinking-exp-01-21 and gemini-2.0-flash\n",
        "\n",
        "run llama or gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKmjLOr--z0S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from google import genai\n",
        "import time\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from huggingface_hub import login\n",
        "\n",
        "\n",
        "def call_gemini_with_interval(client, model, contents, config, interval=20, retries=3, backoff_factor=2):\n",
        "    \"\"\"\n",
        "    Call Google Gemini API with a fixed interval between requests and retry logic for handling errors.\n",
        "\n",
        "    Args:\n",
        "        client (genai.Client): The Google Gemini client.\n",
        "        model (str): The model name (e.g., \"gemini-2.0-flash\").\n",
        "        contents (str): The input prompt or question.\n",
        "        config (dict): Configuration for the API call (e.g., tools, temperature, etc.).\n",
        "        interval (int): Time in seconds to wait between API requests.\n",
        "        retries (int): Number of retries for handling quota exhaustion or other errors.\n",
        "        backoff_factor (int): Factor for exponential backoff in case of retries.\n",
        "\n",
        "    Returns:\n",
        "        response: The response from the Google Gemini API.\n",
        "    \"\"\"\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            # Send the API request\n",
        "            response = client.models.generate_content(\n",
        "                model=model,\n",
        "                contents=contents,\n",
        "                config=config,\n",
        "            )\n",
        "            print(f\"Request succeeded. Waiting {interval} seconds before the next request...\")\n",
        "            time.sleep(interval)  # Wait for the specified interval\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            if \"RESOURCE_EXHAUSTED\" in str(e):\n",
        "                print(f\"Quota exceeded. Retrying in {backoff_factor ** attempt} seconds...\")\n",
        "                time.sleep(backoff_factor ** attempt)\n",
        "            else:\n",
        "                raise e\n",
        "    raise Exception(\"Max retries exceeded. Quota still exhausted.\")\n",
        "\n",
        "\n",
        "def run_baseline(\n",
        "    model_name,\n",
        "    output_file,\n",
        "    qa_file=\"./data/annotated/QA_pairs_1.csv\",\n",
        "    sample_size=100\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate QA baseline answers using either Hugging Face LLaMA or Google Gemini and save the results to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): Model name for LLaMA or Gemini (e.g., \"gemini-2.0-flash\" or \"meta-llama/Llama-3.1-8B-Instruct\").\n",
        "        output_file (str): Path to save the generated answers.\n",
        "        qa_file (str): Path to the QA annotation test set CSV file.\n",
        "        sample_size (int): Number of QA pairs to sample for evaluation.\n",
        "    \"\"\"\n",
        "    # Load QA annotation test set\n",
        "    print(f\"Loading QA file: {qa_file}\")\n",
        "    qa_df = pd.read_csv(qa_file)\n",
        "    qa_df = qa_df.sample(sample_size, random_state=221)\n",
        "    sample_doc_ids = qa_df[\"Doc_id\"].tolist()\n",
        "    sample_questions = qa_df[\"Question\"].tolist()\n",
        "    sample_answers = qa_df[\"Reference_Answers\"].tolist()\n",
        "\n",
        "    # Define the prompt template\n",
        "    template = \"\"\"\n",
        "    You are an expert assistant answering factual questions about various aspects of Pittsburgh or Carnegie Mellon University (CMU), including history, policy, culture, events, and more.\n",
        "    If you do not know the answer, just say \"I don't know.\"\n",
        "\n",
        "    Important Instructions:\n",
        "    - Answer concisely without repeating the question.\n",
        "    - Do **not** use complete sentences. Provide only the word, name, date, or phrase that directly answers the question. For example, given the question \"When was Carnegie Mellon University founded?\", you should only answer \"1900\".\n",
        "\n",
        "    Examples:\n",
        "    Question: Who is Pittsburgh named after?\n",
        "    Answer: William Pitt\n",
        "    Question: What famous machine learning venue had its first conference in Pittsburgh in 1980?\n",
        "    Answer: ICML\n",
        "    Question: What musical artist is performing at PPG Arena on October 13?\n",
        "    Answer: Billie Eilish\n",
        "\n",
        "    Question: {question} \\n\\n\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    # Determine the model type based on the model name\n",
        "    if \"gemini\" in model_name.lower():\n",
        "        # Initialize the Gemini client\n",
        "        print(\"Initializing Google Gemini client...\")\n",
        "        client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\", \"your_api_key_here\")) #  \n",
        "\n",
        "        # Generate answers using Google Gemini\n",
        "        print(\"Generating answers using Google Gemini...\")\n",
        "        generated_answers = []\n",
        "        for question in tqdm(sample_questions):\n",
        "            full_prompt = template.format(question=question)\n",
        "            response = call_gemini_with_interval(\n",
        "                client,\n",
        "                model=model_name,  # Use the provided Gemini model name\n",
        "                contents=full_prompt,\n",
        "                config={},  # {\"tools\": [{\"google_search\": {}}]},\n",
        "                interval=4,  # Wait 4 seconds between requests\n",
        "                retries=3,  # Retry up to 3 times if quota is exceeded\n",
        "                backoff_factor=2  # Exponential backoff for retries\n",
        "            )\n",
        "            # Extract the generated answer\n",
        "            generated_answers.append(response.text)\n",
        "\n",
        "    elif \"llama\" in model_name.lower():\n",
        "        # Login to Hugging Face Hub\n",
        "        print(\"Initializing Hugging Face LLaMA model...\")\n",
        "        login(token=os.getenv(\"HUGGINGFACE_TOKEN\", \"your_huggingface_token_here\")) # \n",
        "\n",
        "        # Load the model and tokenizer\n",
        "        print(f\"Loading LLaMA model: {model_name}\")\n",
        "        model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        tokenizer.padding_side = \"left\"\n",
        "\n",
        "        # Initialize the text generation pipeline\n",
        "        generation_pipe = pipeline(\n",
        "            \"text-generation\",\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            torch_dtype=torch.float16\n",
        "        )\n",
        "\n",
        "        # Generate answers using LLaMA\n",
        "        print(\"Generating answers using LLaMA...\")\n",
        "        generated_answers = []\n",
        "        for question in tqdm(sample_questions):\n",
        "            full_prompt = template.format(question=question)\n",
        "            messages = [\n",
        "                {\"role\": \"user\", \"content\": full_prompt},\n",
        "            ]\n",
        "            output = generation_pipe(messages, max_new_tokens=50)\n",
        "            generated_answers.append(output[0][\"generated_text\"][1]['content'])\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model_name. Please ensure it contains 'gemini' or 'llama'.\")\n",
        "\n",
        "    # Save results to a CSV file\n",
        "    results_df = pd.DataFrame({\n",
        "        \"Doc_id\": sample_doc_ids,\n",
        "        \"Question\": sample_questions,\n",
        "        \"Reference_Answers\": sample_answers,\n",
        "        \"Generated_Answer\": generated_answers,\n",
        "    })\n",
        "    results_df.to_csv(output_file, index=False)\n",
        "    print(f\"Results saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQhdVz66-6GB"
      },
      "outputs": [],
      "source": [
        "run_baseline(\n",
        "    model_name=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
        "    output_file=\"./output/llama32_3B_baseline.csv\",\n",
        "    qa_file=\"./data/annotated/QA_pairs_1.csv\",\n",
        "    sample_size=100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvzSSctq-_Wz",
        "outputId": "b851205d-71c3-4ac9-81cc-406ba1589c04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading QA file: ./data/annotated/QA_pairs_1.csv\n",
            "Initializing Google Gemini client...\n",
            "Generating answers using Google Gemini...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 1/100 [00:09<15:28,  9.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 2/100 [00:17<14:17,  8.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 3/100 [00:22<11:31,  7.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 4/100 [00:28<10:15,  6.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 5/100 [00:33<09:25,  5.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 6/100 [00:41<10:45,  6.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 7/100 [00:46<09:30,  6.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 8/100 [00:52<09:11,  5.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 9/100 [00:57<08:32,  5.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 10/100 [01:03<08:42,  5.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 11/100 [01:12<09:56,  6.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 12/100 [01:17<09:21,  6.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 13/100 [01:25<09:41,  6.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 14/100 [01:32<09:59,  6.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 15/100 [01:46<12:49,  9.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 16/100 [01:51<11:07,  7.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 17/100 [01:56<09:42,  7.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 18/100 [02:02<08:58,  6.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 19/100 [02:07<08:21,  6.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 20/100 [02:12<07:44,  5.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 21/100 [02:17<07:19,  5.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 22/100 [02:27<08:45,  6.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 23/100 [02:32<08:14,  6.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 24/100 [02:37<07:31,  5.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 25/100 [02:42<07:05,  5.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 26/100 [02:47<06:51,  5.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 27/100 [02:52<06:28,  5.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 28/100 [02:57<06:10,  5.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 29/100 [03:03<06:34,  5.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 30/100 [03:10<06:56,  5.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 31/100 [03:16<06:36,  5.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 32/100 [03:22<06:53,  6.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 33/100 [03:33<08:21,  7.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 34/100 [03:38<07:23,  6.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 35/100 [03:44<07:01,  6.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 36/100 [03:54<07:53,  7.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 37/100 [04:00<07:18,  6.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 38/100 [04:05<06:37,  6.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 39/100 [04:10<06:04,  5.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 40/100 [04:14<05:39,  5.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 41/100 [04:21<05:52,  5.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 42/100 [04:27<05:37,  5.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 43/100 [04:32<05:17,  5.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 44/100 [04:38<05:25,  5.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 45/100 [04:44<05:25,  5.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 46/100 [04:50<05:10,  5.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 47/100 [04:57<05:37,  6.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 48/100 [05:03<05:14,  6.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 49/100 [05:08<04:53,  5.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 50/100 [05:12<04:32,  5.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 51/100 [05:23<05:38,  6.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 52/100 [05:30<05:41,  7.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 53/100 [05:36<05:07,  6.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 54/100 [05:48<06:15,  8.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 55/100 [05:55<05:58,  7.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 56/100 [06:02<05:33,  7.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 57/100 [06:10<05:40,  7.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 58/100 [06:16<04:57,  7.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 59/100 [06:21<04:29,  6.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 60/100 [06:26<04:04,  6.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 61/100 [06:32<03:53,  5.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 62/100 [06:38<03:50,  6.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 63/100 [06:48<04:28,  7.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 64/100 [06:54<04:06,  6.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 65/100 [07:01<03:57,  6.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 66/100 [07:06<03:35,  6.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 67/100 [07:13<03:36,  6.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 68/100 [07:22<03:55,  7.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 69/100 [07:27<03:26,  6.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 70/100 [07:32<03:03,  6.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 71/100 [07:44<03:50,  7.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 72/100 [07:49<03:16,  7.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 73/100 [07:58<03:23,  7.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 74/100 [08:03<02:55,  6.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 75/100 [08:07<02:33,  6.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 76/100 [08:15<02:35,  6.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 77/100 [08:24<02:50,  7.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 78/100 [08:29<02:28,  6.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 79/100 [08:36<02:20,  6.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 80/100 [08:41<02:03,  6.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 81/100 [08:48<02:05,  6.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 82/100 [08:54<01:51,  6.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 83/100 [08:59<01:40,  5.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 84%|████████▍ | 84/100 [09:05<01:33,  5.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 85%|████████▌ | 85/100 [09:10<01:24,  5.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 86%|████████▌ | 86/100 [09:15<01:15,  5.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 87/100 [09:20<01:08,  5.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 88/100 [09:27<01:09,  5.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 89%|████████▉ | 89/100 [09:35<01:13,  6.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 90/100 [09:41<01:04,  6.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 91%|█████████ | 91/100 [09:47<00:56,  6.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 92/100 [09:52<00:47,  5.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 93/100 [10:03<00:52,  7.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▍| 94/100 [10:08<00:39,  6.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▌| 95/100 [10:15<00:33,  6.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 96/100 [10:20<00:25,  6.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 97%|█████████▋| 97/100 [10:28<00:20,  6.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 98/100 [10:41<00:17,  8.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 99%|█████████▉| 99/100 [10:46<00:07,  7.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request succeeded. Waiting 4 seconds before the next request...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [10:51<00:00,  6.52s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to ./output/gemini_2_flash_thinking_baseline.csv\n"
          ]
        }
      ],
      "source": [
        "run_baseline(\n",
        "    model_name=\"gemini-2.0-flash-thinking-exp-01-21\",\n",
        "    output_file=\"./output/gemini_2_flash_thinking_baseline.csv\",\n",
        "    #qa_file=\"./data/annotated/QA_pairs_1.csv\",\n",
        "    #sample_size=100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "db6c8d75ef504c7ba2cbb36c84598e2d",
            "15defe94b6ad41a5bb046650a69bac65",
            "9613f0e8b07344cd93f587e72d03ecb3",
            "9058b21c35624f6a8f619a4ba6e4d88f",
            "0e52879b43c241da8c4cac62b2e026ba",
            "b7da7914942d4cac9306987b82896839",
            "59cb883cb462480ca4368eea286a91b7",
            "32fc98fb7a534c23b1fed758d2ac9286",
            "a3c3bb6c442944a393055c77e075c104",
            "55ca116eb26d499ea57b0b07efa7816b",
            "e420e742554e4781ae6db276b79dfaba",
            "c1ae6e8cf31f46ad92897499e9dc689e",
            "b5164e9662fc4cd9af7f66df84e25f1a",
            "c754bd4b64dd46be85b8cb1c0f4ab28b",
            "e4cadcf13f3844729f66c6a04d970ad2",
            "c6b02be5cf9f430c9811b5770f5deb4a",
            "d99939bd4fc246b6a634bcc25cefc1f5",
            "5b2419dbf5da48138d913bdd405471a2",
            "c0452c8c844a4e5a9ab408e5a836335d",
            "a181d39103db4087b1e03d5d63956a89",
            "6db2e60a7a5f4a1abb0c6dd6413ecc5f",
            "09ea6cdd1362402da49bdb68379825a9",
            "71651067fbd84691a774020195300fa7",
            "d032cd63bab84a7caa0dd253d8ef1b66",
            "c67a25c515184744b299cbe910ac8350",
            "a08bbce15bba49009232ec8b173495ea",
            "d9c148e579514ed387383852fece7d06",
            "eba3faf5887248e2bb6c562d121b037c",
            "8a3c2ab70fc2480bb9ab9c14de874e63",
            "2b315b24504c49938e595075de9b84c5",
            "07d40eea6ecc433186417740fa794f98",
            "8380f87e994e4d0bbadc04440ce3f977",
            "9a51fed00b504d68a0ccff8cce91f56f",
            "0039e3068dae479986bda45c8b54fcde",
            "66e5da835a2740f7bfaf1b2e0200147a",
            "18f2bf1e5c734626a140d4f3770b4c9d",
            "5e0d60abda5f4f9694ebea2549ccc437",
            "e17ba1e0709340d89b36bbf27846d6bb",
            "40c59e702f7949018d57463885266acd",
            "a565637420904138ae2b6f843b712386",
            "e64c3cb814bd4b339ebd0693da93ac1d",
            "e9d4830db4e444b7971eb07d9c8c815b",
            "dc044fc905984a37ae33f29ff5b652bd",
            "0d926d354670437b876f333efdefc634",
            "d9fddd0d10954725992bd7253a25acbb",
            "533c077541674f69a1e2cd85f67176e7",
            "fdbffb71477f480e8e5641bf01ea52f5",
            "1504dc1522b1427bba3c92cbf4d9c130",
            "6dd052d18d2a455d833b4f4e702ed990",
            "98011c67291c489a8edffd802e1ff0cd",
            "4ae234ff21f747bf99916f8f3a7205c7",
            "39598ccf83f34df3ba8142178f85a907",
            "0af0674984b143b1ac874ef89d838142",
            "47767461d43b4212a6fdf916ea0c2bdd",
            "3fdc5ffbc9624eef8fccef7b8bf41087",
            "18342057008243238339f374585d37e7",
            "22a24e3cc64045a4a4d0113045242427",
            "2a9047d2e09a44b3ace787beb3d669cd",
            "690124a7cf5444eca1367b8e2506490a",
            "8790efa86b7f4096b40aef8737830f85",
            "e54ebd842cb64bb49da7bd8d4c1e18d1",
            "d620ae701f1f48f2b86903d1b47f6bc5",
            "961385fff2244d7c807eef1a0b52e0fd",
            "a7d23dd739a5432993376be99692368d",
            "1fb46c63e20f488da8cc7b5e3bdfbc68",
            "3c03b9af61f648729c04a010d4b70d86",
            "39d8a12ae03447e3bd6d88b6ddfd6bf6",
            "7df1b2a7c3774dd2848d57aeb80d9648",
            "8adadf928409437484739b11f9ed0b88",
            "03a5e74ef2064b84bdc7e06c219a07a8",
            "62fd14e31f304521bb235374949feed2",
            "5d4252ca5f0a486784ff167b21fd3d97",
            "2a3bcdb42d234c88a7b2103cdd6ecbc9",
            "7cf90b4f2e3f41659dc7a659798f0d75",
            "7009134e970b4410adfc3c444c20510d",
            "f95eeeb8ee364b7c984a2eb244e87d6a",
            "5ad6f5d1b83f40ddac79c6f1abc33272",
            "66fde7ee809541af955a5dcca0381761",
            "6bdd3c173f084784bab54af314252143",
            "2b47360f2f6149a4a18607b42a765f5c",
            "72c8ecd4ccdd4e2491dab5db5e4d4168",
            "cb5949943ebe4c78a5fc3dc18ff1fa2a",
            "36c9ff54e42d4819abefd32b44ab61cf",
            "3db90680d035416daa3dbb4c7ebc0aee",
            "be190bbfde4146de9dfdd64e649cf740",
            "ecd1bfa6a5894910bea10b6ebceecfa6",
            "d0e600c20a2344f8af088d64f1c93df8",
            "a63bf321c45d4270b8d7bbf94a32833b",
            "06eb0292aa7d40d58d33279a99f99471",
            "0bbec7780d854ea49d20c9a99cd0b044",
            "a5b5e11af5814272b05445f635b5c044",
            "a85f7abf273c4137b0cd92e93a478955",
            "c107d3c693d149cc960c4dd957d0d53e",
            "d5f7bd0d13e44a1cba716a09a05455ae",
            "b1ef786a54ae4b8a805f59b066fc1481",
            "58c04aedfd5c4bca8fa1b8cacfb8565d",
            "7b825ec38e17464795c10488f6d0502a",
            "edd995eacd64499397ecf4c52ae47b57",
            "40d948db3e9f4a0bac5c4eca80fa82ca",
            "546c48b7d88c4b189c2b7c83b82dd371",
            "d247f7650c684e32aeb6a4984be44fa1",
            "6e3b7056729e44998133794bc63a7216",
            "01c4cc346f854126aee98d6fb8b55457",
            "f99eacdd8f1e4acebaaef72a4813ef81",
            "55171bc346574d3f8dd48ae7edacdbc3",
            "da9c60b27cea4096af0d5e4c1e1df8e0",
            "c2f578194f354923b7f8779ab5cdf53f",
            "aea1deb2ccd146bb801718a89f565c6f",
            "13066469ec0848a28b43a7439b31e56d",
            "c0d249358d5347c79691c0ae381a4f89",
            "86a9f438ffe34cb08bcdbaa05877bd30",
            "eef8f36aaef54125ab5f6b81f8e57546",
            "edd462cbc93141338d3e54e01691355d",
            "260c82d9385745b9ba02f6bc47ddfc6b",
            "8ad0bec6d72b4e56899f4b0d0596259c",
            "9f3832d14f2346f3b136a670be35162a",
            "c31402a2326745a3afa0220540c32713",
            "60cdaeeaaac14da5b4eaf57e1f4644f5",
            "0254f23c13d6474fb5ea3c8ae1fdcd1e",
            "795d0861e65d404b8a13236a4ccf3729",
            "e23f5d57fbbe420c815990c009cbdd44",
            "9fe7236e6866407182f1c9c59f8f68f8",
            "f82f9eeeae15479ebef84b709918d675",
            "4a6a102172fc44168219d49608e1e01e",
            "96f71cb6556640ee935561bea891b2d3",
            "2c9d2af360154331bc7c5e29bf15a555",
            "63729a0651104a0e93dc4cbbcbf709b0",
            "412b6606b4a24977b247c0ff41eb0cd9",
            "848e843f54f9405f8f568310133186cd",
            "bd1f288a753b4e06bca7dd8447bc586e",
            "e45075cd344f4ee59491418922cf238f",
            "db26d584f102480a94b1bcd889f05b17",
            "6a6fe88b7a0e49889dea3a46878ea7c4",
            "4608396203b4472288f65f2b647f0a0a",
            "ed19a90ba21640648a1e1fb0256f2bf1",
            "6456b1366cb341bd8b4f77d14bc02ee6",
            "da7c25fc6eca4d1180be8391f550f6ec",
            "e88b0074302a46f4b52cdb2d7a30ea44",
            "99197cf92ae045b4a43bf1c3a44ef8c9",
            "5fcb24923e6d4dd788f4504fb5c8408b",
            "f33e94ca28a04c09b743b1194aed839c",
            "8bdf3eb68ced40ae9251e52a9d30d13e",
            "6a215822c4b0461f81b439eb366a7a96",
            "b985c9ea973547f3bf9c18781eb82585",
            "5170eb0cea444079bb5ca8afe0d917c3",
            "9f215cef376943b8bfcf9618b48bf2eb",
            "f08012418f9f48659e6d2a947c3f1958",
            "a15e9012a38e43619dc8b5a9f5dc6a33",
            "7d45daf6281147f5a3f5c0ec60782f25",
            "9ae80724d7a045b38ffd31b1ff1ad4b1",
            "f09e9fb780334111ba8f06cf36477021",
            "e7b8bd877be1430e823b29e51626d0eb",
            "feff635f51404877941a8145eb0b0376",
            "60b1863ecbe14507bac84d36be4b0b75",
            "49c8a195d1b949868225dbecc83e4f86",
            "c753370714f549e6af7f17addc071d55",
            "4ac4cece48484311bfbab71e13df4851",
            "04e0d89e72f84a9d8b686cf32032f8e6",
            "e9f154b9344c4d888a196496fbf77b73",
            "c9907536375f48539bf303089ac28879",
            "fe3be0dfdb6f4fceaf587260aad3ecb9",
            "dc08c7bb654b48bebcb1db22916e583c",
            "163350bc7e6d4c4d909b66bec71e5a6f",
            "26d481b3654945ea89521909d5c5bf13",
            "fc25c964b7e94b2593e514b1022d273f",
            "47a2b82d104c41c08e29ef5118c338ac",
            "1472940dbb56400394be2055cc3de6f8",
            "0f46fba9d97c4840a25171a4bc8c335e",
            "8b566ab6447f4f789eec3e645a4ac3aa",
            "52f5b00acf3743b4ab4c553b650472f4",
            "1d968fe9abed4d2498af1422bfb3e1a9",
            "eacba7ee06cb4db4aafd5a7b00875f06",
            "68cbfb783e8b41d999861d7ffdc0c1b0",
            "543683a01eff44d9a2228152860bfb73",
            "74302353dc5042fe8b69535ae43865ab",
            "8882afef7788422282a9e9e1a7c6f35b",
            "619b5c69e7e249ba8743fa0b78525884",
            "2868f96cef9e47708d1ac335b245022b",
            "7be2de4ba6dc47ca93023d814feea3fd",
            "a75b7c87c77d4895821cff8c90f38e5a",
            "6b10a4adcfac4d449db530d9bad6bde0",
            "6ff9748bbdae4526813d39f7388d3f32",
            "b9d2f9049c964ec99a8b4642ffb7518f",
            "54e565834b7546618a2a3fe761d6133f",
            "17ca8e9997d147e48d49cb76e615c692",
            "0226aadba1744c24904ca05d4b7c6d48",
            "bac91920ddf44ee09dc12f526ebcf79e",
            "9c88448c2fe845258ea7ff66fcc815ee",
            "ae2a46795e5943b0aa5382f937f7978c",
            "5c1fed9d3ce94353a15d8e9332e7cc13",
            "c849f13aecf0402ab54a8d53ee8e4edf",
            "7f74f5bc222d400982c4469a63a47e98",
            "188aa85ee265439991be81b912d1739f",
            "eee57d05ced241698d4c4bc0996d8d03",
            "0dfe55e8e2ca422ba668f44567678a7d",
            "1a0ce4aba7114feb8e9c4fe033af836c",
            "ffd22a2a10674fd986e9e1d055e95bca",
            "1d3f0e1f3b90455e9aa935280527c0d2",
            "3e6e2995a94d42209a79876cf84104c8",
            "ca12f8aa82c847bb81fd6a1a4a59cc8c",
            "5837fe949dd1467ebb643b74bd1d96b3",
            "392b323400294ed7856adcc234b878b0",
            "5f2378fa879e42b4aa7c393c1f6ca59a",
            "a27bdbb3276c4b8e820a0b39abb4d920",
            "42d3bb028e8341309ac46747f85d29a4",
            "335bcaf2cc454aa49622d9ada481aba5",
            "f8f34621275247d48e8d43efe2bae3a0",
            "48f77526c05047b8bff9cc70a7f29c09",
            "6a2af8bb38a240fabf2a9fe61a9ddfed",
            "186a0652e81945419dcd03ba5d69c5b6",
            "f3ed9b5b465b4d3c965aadffabf1a27b",
            "a57d80d544dd469f8d72837e97d5ac73",
            "ada5e0341f7540d88e7ec973a14db44e",
            "6d66ab6b53164fb0ba557d9541b4dfe4",
            "8728bdd045f1468b93dec4954adf63eb",
            "e29f27a7df9c44f4b5f4cafd3a78ca91",
            "f92ae930a254441db271925b5481bd49",
            "557a4080c83e49b08e86d81be931adbf",
            "ae95a6d4666040a7bb8d0b64da1c922f",
            "c3b5701ae3a84de5a0912a72d8c21857",
            "cf959e8c403443e6b5e57f79885179a5",
            "e7547fbd3c164f88a169da2f9c5a73f7",
            "7825aa4b4b054fbca1a461559ec0b483",
            "fc841159993d4c45ad007be2a178d4bb",
            "d5ea530958db4d018fdb0ee97aa60cbc",
            "e544d31f209d41e49b49e2dbadff89b1",
            "bf1e055270a447b1a46e778ac45adaf0",
            "9ab39aa2535b4c5f8ac04ed152066890",
            "5715365967aa4497ade0cd282f48be04",
            "4b0fede05bfa46379f4359f733801f01",
            "f8d7d542140543aeb384c45997401a09",
            "684afb340de64dd7b164783328f3f4b3",
            "7ad3630bf9d644dab0355dd5c62141cb",
            "c77de10f318f4440a0bb7da1dfd9a830",
            "236993cbefd24f51971b1c811ee0fdaf",
            "4b860fc3477748c4973e9fb45677bae1",
            "e1568fa99dfe4cd2832f50a9cdad460a",
            "f9b85861796b4c1388eae9a06c5e39f5",
            "591b3d7ef4cf4ca9ad36e13ffee3ba3a",
            "12f47e59ed484644867879ef9721cd02",
            "f6ff0e6a97fd474893b4c29c67ea3c05",
            "bf74b6a79c9a4ad082352ce88d509497"
          ]
        },
        "id": "8sK44qKbCa_C",
        "outputId": "8bcff4e0-ae8e-40b9-cd81-41602db42cc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running baseline for model: meta-llama/Llama-3.2-3B-Instruct\n",
            "Loading QA file: ./data/annotated/QA_pairs_1.csv\n",
            "Initializing Hugging Face LLaMA model...\n",
            "Loading LLaMA model: meta-llama/Llama-3.2-3B-Instruct\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db6c8d75ef504c7ba2cbb36c84598e2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1ae6e8cf31f46ad92897499e9dc689e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71651067fbd84691a774020195300fa7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0039e3068dae479986bda45c8b54fcde",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9fddd0d10954725992bd7253a25acbb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18342057008243238339f374585d37e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39d8a12ae03447e3bd6d88b6ddfd6bf6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66fde7ee809541af955a5dcca0381761",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06eb0292aa7d40d58d33279a99f99471",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "546c48b7d88c4b189c2b7c83b82dd371",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating answers using LLaMA...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 10/100 [00:03<00:18,  4.78it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "100%|██████████| 100/100 [00:21<00:00,  4.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to ./output/llama32_3B_baseline.csv\n",
            "Completed baseline for model: meta-llama/Llama-3.2-3B-Instruct\n",
            "\n",
            "Running baseline for model: meta-llama/Llama-3.1-8B-Instruct\n",
            "Loading QA file: ./data/annotated/QA_pairs_1.csv\n",
            "Initializing Hugging Face LLaMA model...\n",
            "Loading LLaMA model: meta-llama/Llama-3.1-8B-Instruct\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86a9f438ffe34cb08bcdbaa05877bd30",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fe7236e6866407182f1c9c59f8f68f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a6fe88b7a0e49889dea3a46878ea7c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b985c9ea973547f3bf9c18781eb82585",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49c8a195d1b949868225dbecc83e4f86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47a2b82d104c41c08e29ef5118c338ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "619b5c69e7e249ba8743fa0b78525884",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c88448c2fe845258ea7ff66fcc815ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e6e2995a94d42209a79876cf84104c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "186a0652e81945419dcd03ba5d69c5b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf959e8c403443e6b5e57f79885179a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "684afb340de64dd7b164783328f3f4b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating answers using LLaMA...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:21<00:00,  4.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to ./output/llama31_8B_baseline.csv\n",
            "Completed baseline for model: meta-llama/Llama-3.1-8B-Instruct\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define the models and output file names\n",
        "models = [\n",
        "    (\"meta-llama/Llama-3.2-3B-Instruct\", \"./output/llama32_3B_baseline.csv\"),\n",
        "    (\"meta-llama/Llama-3.1-8B-Instruct\", \"./output/llama31_8B_baseline.csv\"),\n",
        "    (\"gemini-2.0-flash\", \"./output/gemini_2_flash_baseline.csv\"),\n",
        "    (\"gemini-2.0-flash-thinking-exp-01-21\", \"./output/gemini_2_flash_thinking_baseline.csv\")\n",
        "]\n",
        "\n",
        "# Run the function for each model\n",
        "for model_name, output_file in models:\n",
        "    print(f\"Running baseline for model: {model_name}\")\n",
        "    run_baseline(\n",
        "        model_name=model_name,\n",
        "        output_file=output_file#,\n",
        "        #qa_file=\"./data/annotated/QA_pairs_1.csv\",\n",
        "        #sample_size=100\n",
        "    )\n",
        "    print(f\"Completed baseline for model: {model_name}\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
